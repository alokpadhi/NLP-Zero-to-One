{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "agFfrAijbmXX"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2pMEyZ0cQwu"
      },
      "source": [
        "SEED = 1234"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae7aYeLTcR7p"
      },
      "source": [
        "def set_seeds(seed=1234):\n",
        "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) # multi-GPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng3wJLYPcTnQ"
      },
      "source": [
        "# Set seeds for reproducibility\n",
        "set_seeds(seed=SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pt1yJU0JcUqb",
        "outputId": "b140c62a-a972-4746-c16c-9a659593e0a6"
      },
      "source": [
        "# Set device\n",
        "cuda = True\n",
        "device = torch.device('cuda' if (\n",
        "    torch.cuda.is_available() and cuda) else 'cpu')\n",
        "torch.set_default_tensor_type('torch.FloatTensor')\n",
        "if device.type == 'cuda':\n",
        "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "print (device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "WPGL4m9EcVxJ",
        "outputId": "db8cd794-7943-4c52-f879-1319c8ff9dfd"
      },
      "source": [
        "# Load data\n",
        "url = \"https://raw.githubusercontent.com/GokuMohandas/MadeWithML/main/datasets/news.csv\"\n",
        "df = pd.read_csv(url, header=0) # load\n",
        "df = df.sample(frac=1).reset_index(drop=True) # shuffle\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sharon Accepts Plan to Reduce Gaza Army Operat...</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Internet Key Battleground in Wildlife Crime Fight</td>\n",
              "      <td>Sci/Tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>July Durable Good Orders Rise 1.7 Percent</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Growing Signs of a Slowing on Wall Street</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The New Faces of Reality TV</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  category\n",
              "0  Sharon Accepts Plan to Reduce Gaza Army Operat...     World\n",
              "1  Internet Key Battleground in Wildlife Crime Fight  Sci/Tech\n",
              "2          July Durable Good Orders Rise 1.7 Percent  Business\n",
              "3          Growing Signs of a Slowing on Wall Street  Business\n",
              "4                        The New Faces of Reality TV     World"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7vqJTCscXXQ"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9eRnW1mcZTZ",
        "outputId": "d0289a9e-5a49-4993-f54f-62010831da8f"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "STOPWORDS = stopwords.words('english')\n",
        "print (STOPWORDS[:5])\n",
        "porter = PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "['i', 'me', 'my', 'myself', 'we']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAnhf-cScaXR"
      },
      "source": [
        "def preprocess(text, stopwords=STOPWORDS):\n",
        "    \"\"\"Conditional preprocessing on our text unique to our task.\"\"\"\n",
        "    # Lower\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove stopwords\n",
        "    pattern = re.compile(r'\\b(' + r'|'.join(stopwords) + r')\\b\\s*')\n",
        "    text = pattern.sub('', text)\n",
        "\n",
        "    # Remove words in paranthesis\n",
        "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
        "\n",
        "    # Spacing and filters\n",
        "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\n",
        "    text = re.sub('[^A-Za-z0-9]+', ' ', text) # remove non alphanumeric chars\n",
        "    text = re.sub(' +', ' ', text)  # remove multiple spaces\n",
        "    text = text.strip()\n",
        "\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nYMjQz0mcb_Q",
        "outputId": "78140631-67de-441a-ac10-676b10e5f6b3"
      },
      "source": [
        "# Sample\n",
        "text = \"Great week for the NYSE!\"\n",
        "preprocess(text=text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'great week nyse'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muj8StbQcdMA",
        "outputId": "5def114d-d448-4235-aebf-ad9cc314f463"
      },
      "source": [
        "# Apply to dataframe\n",
        "preprocessed_df = df.copy()\n",
        "preprocessed_df.title = preprocessed_df.title.apply(preprocess)\n",
        "print (f\"{df.title.values[0]}\\n\\n{preprocessed_df.title.values[0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sharon Accepts Plan to Reduce Gaza Army Operation, Haaretz Says\n",
            "\n",
            "sharon accepts plan reduce gaza army operation haaretz says\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JqCO3QDce7f"
      },
      "source": [
        "import collections\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZHihC4LchPg"
      },
      "source": [
        "TRAIN_SIZE = 0.7\n",
        "VAL_SIZE = 0.15\n",
        "TEST_SIZE = 0.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlFaEZwPciQB"
      },
      "source": [
        "def train_val_test_split(X, y, train_size):\n",
        "    \"\"\"Split dataset into data splits.\"\"\"\n",
        "    X_train, X_, y_train, y_ = train_test_split(X, y, train_size=TRAIN_SIZE, stratify=y)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size=0.5, stratify=y_)\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls7pXDl8cjj7"
      },
      "source": [
        "# Data\n",
        "X = preprocessed_df[\"title\"].values\n",
        "y = preprocessed_df[\"category\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-21X97qckgH",
        "outputId": "29f0a2d1-d633-4958-8928-2a07482abe17"
      },
      "source": [
        "# Create data splits\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\n",
        "    X=X, y=y, train_size=TRAIN_SIZE)\n",
        "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
        "print (f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "print (f\"Sample point: {X_train[0]} → {y_train[0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: (84000,), y_train: (84000,)\n",
            "X_val: (18000,), y_val: (18000,)\n",
            "X_test: (18000,), y_test: (18000,)\n",
            "Sample point: extinct humans left louse legacy → Sci/Tech\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxTLbEHrclbw"
      },
      "source": [
        "import itertools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgXvofOtcnDo"
      },
      "source": [
        "class LabelEncoder(object):\n",
        "    def __init__(self, class_to_index={}):\n",
        "        self.class_to_index = class_to_index\n",
        "        self.index_to_class = {v:k for k,v in self.class_to_index.items()}\n",
        "        self.classes = list(self.class_to_index.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.class_to_index)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<LabelEncoder(num_classes={len(self)})>\"\n",
        "\n",
        "    def fit(self, y):\n",
        "        classes = np.unique(y)\n",
        "\n",
        "        for i, class_ in enumerate(classes):\n",
        "            self.class_to_index[class_] = i\n",
        "        self.index_to_class = {v:k for k, v in self.class_to_index.items()}\n",
        "        self.classes = list(self.class_to_index.keys())\n",
        "\n",
        "        return self\n",
        "    \n",
        "    def encode(self, y):\n",
        "        encoded = np.zeros(len(y), dtype=int)\n",
        "        for i, item in enumerate(y):\n",
        "            encoded[i] = self.class_to_index[item]\n",
        "        return encoded\n",
        "\n",
        "    def decode(self, y):\n",
        "        classes = []\n",
        "        for i, item in enumerate(y):\n",
        "            classes.append(self.index_to_class[item])\n",
        "        return classes\n",
        "\n",
        "    def save(self, fp):\n",
        "        with open(fp, 'w') as fp:\n",
        "            contents = {'class_to_index': self.class_to_index}\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, fp):\n",
        "        with open(fp, 'r') as fp:\n",
        "            kwargs = json.load(fp=fp)\n",
        "        return cls(**kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj0yZIJ1eXmv",
        "outputId": "3dc44fa4-1cf0-4785-972e-855c358bcece"
      },
      "source": [
        "# Encode\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_train)\n",
        "NUM_CLASSES = len(label_encoder)\n",
        "label_encoder.class_to_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Business': 0, 'Sci/Tech': 1, 'Sports': 2, 'World': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANiM7hBxeZ0N",
        "outputId": "88589e0e-27c1-4cec-e521-404f9ffaa972"
      },
      "source": [
        "# Convert labels to tokens\n",
        "print (f\"y_train[0]: {y_train[0]}\")\n",
        "y_train = label_encoder.encode(y_train)\n",
        "y_val = label_encoder.encode(y_val)\n",
        "y_test = label_encoder.encode(y_test)\n",
        "print (f\"y_train[0]: {y_train[0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train[0]: Sci/Tech\n",
            "y_train[0]: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGwGZaXpebrN",
        "outputId": "ccb20e57-76eb-4ed7-a1a5-06eaa945fe83"
      },
      "source": [
        "# Class weights\n",
        "counts = np.bincount(y_train)\n",
        "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
        "print (f\"counts: {counts}\\nweights: {class_weights}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "counts: [21000 21000 21000 21000]\n",
            "weights: {0: 4.761904761904762e-05, 1: 4.761904761904762e-05, 2: 4.761904761904762e-05, 3: 4.761904761904762e-05}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w-prOmaedy1"
      },
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "from more_itertools import take"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVATV9kYefvn"
      },
      "source": [
        "class Tokenizer(object):\n",
        "    def __init__(self, char_level, num_tokens=None, pad_token='<PAD>', \n",
        "                 oov_token='<UNK>', token_to_index=None):\n",
        "        self.char_level = char_level\n",
        "        self.separator = '' if self.char_level else ' '\n",
        "        if num_tokens: num_tokens -= 2\n",
        "        self.num_tokens = num_tokens\n",
        "        self.pad_token = pad_token\n",
        "        self.oov_token = oov_token\n",
        "        if not token_to_index:\n",
        "            token_to_index = {pad_token: 0, oov_token: 1}\n",
        "        self.token_to_index = token_to_index\n",
        "        self.index_to_token = {v:k for k, v in self.token_to_index.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_to_index)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Tokenizer(num_tokens={len(self)})>\"\n",
        "\n",
        "    def fit_on_texts(self, texts):\n",
        "        if not self.char_level:\n",
        "            texts = [text.split(\" \") for text in texts]\n",
        "        all_tokens = [token for text in texts for token in text]\n",
        "        counts = Counter(all_tokens).most_common(self.num_tokens)\n",
        "        self.min_token_freq = counts[-1][-1]\n",
        "        for token, count in counts:\n",
        "            index = len(self)\n",
        "            self.token_to_index[token] = index\n",
        "            self.index_to_token[index] = token\n",
        "\n",
        "        return self\n",
        "\n",
        "    def texts_to_sequences(self, texts):\n",
        "        sequences = []\n",
        "        for text in texts:\n",
        "            if not self.char_level:\n",
        "                text = text.split(' ')\n",
        "            sequence = []\n",
        "            for token in text:\n",
        "                sequence.append(self.token_to_index.get(\n",
        "                    token, self.token_to_index[self.oov_token]\n",
        "                ))\n",
        "            sequences.append(np.asarray(sequence))\n",
        "\n",
        "        return sequences\n",
        "\n",
        "    def sequences_to_texts(self, sequences):\n",
        "        texts = []\n",
        "        for sequence in sequences:\n",
        "            text = []\n",
        "            for index in sequence:\n",
        "                text.append(self.index_to_token.get(\n",
        "                    index, self.oov_token\n",
        "                ))\n",
        "            texts.append(self.separator.join([token for token in text]))\n",
        "        return texts\n",
        "\n",
        "    def save(self, fp):\n",
        "        with open(fp, 'w') as fp:\n",
        "            contents = {\n",
        "                'char_level': self.char_level,\n",
        "                'oov_token': self.oov_token,\n",
        "                'token_to_index': self.token_to_index\n",
        "            }\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "    \n",
        "    @classmethod\n",
        "    def load(cls, fp):\n",
        "        with open(fp, 'r') as fp:\n",
        "            kwargs = json.load(fp=fp)\n",
        "        return cls(**kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "721ZL40XiOUT",
        "outputId": "f2165b5f-3428-4102-c374-98aa541e88a9"
      },
      "source": [
        "# Tokenize\n",
        "tokenizer = Tokenizer(char_level=False, num_tokens=5000)\n",
        "tokenizer.fit_on_texts(texts=X_train)\n",
        "VOCAB_SIZE = len(tokenizer)\n",
        "print (tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Tokenizer(num_tokens=5000)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMad-VqmiRM5",
        "outputId": "88c9f1b3-e8e1-47ec-ab21-d302448e6976"
      },
      "source": [
        "# Sample of tokens\n",
        "print (take(5, tokenizer.token_to_index.items()))\n",
        "print (f\"least freq token's freq: {tokenizer.min_token_freq}\") # use this to adjust num_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('<PAD>', 0), ('<UNK>', 1), ('39', 2), ('b', 3), ('gt', 4)]\n",
            "least freq token's freq: 14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N6bGpwIiS35",
        "outputId": "77841f52-b826-4dc1-c4a6-596c8d752359"
      },
      "source": [
        "# Convert texts to sequences of indices\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "preprocessed_text = tokenizer.sequences_to_texts([X_train[0]])[0]\n",
        "print (\"Text to indices:\\n\"\n",
        "    f\"  (preprocessed) → {preprocessed_text}\\n\"\n",
        "    f\"  (tokenized) → {X_train[0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text to indices:\n",
            "  (preprocessed) → <UNK> humans left <UNK> legacy\n",
            "  (tokenized) → [   1 2038  963    1 3257]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjWbnUAIiUu6"
      },
      "source": [
        "def pad_sequences(sequences, max_seq_len=0):\n",
        "    \"\"\"Pad sequences to max length in sequence.\"\"\"\n",
        "    max_seq_len = max(max_seq_len, max(len(sequence) for sequence in sequences))\n",
        "    padded_sequences = np.zeros((len(sequences), max_seq_len))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        padded_sequences[i][:len(sequence)] = sequence\n",
        "    return padded_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0kxFBUDikuf",
        "outputId": "ca63667e-2554-4ca9-a3e8-c1ab4365ee7a"
      },
      "source": [
        "# 2D sequences\n",
        "padded = pad_sequences(X_train[0:3])\n",
        "print (padded.shape)\n",
        "print (padded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 7)\n",
            "[[1.000e+00 2.038e+03 9.630e+02 1.000e+00 3.257e+03 0.000e+00 0.000e+00]\n",
            " [1.313e+03 2.680e+02 3.670e+02 9.860e+02 1.000e+00 2.680e+02 0.000e+00]\n",
            " [4.490e+02 7.000e+01 9.640e+02 1.000e+00 5.000e+01 1.341e+03 1.678e+03]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCHC4zRDimY3",
        "outputId": "0e148da9-8dce-41b0-d6e9-e7d467b8fc43"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([   1, 2038,  963,    1, 3257]),\n",
              " array([1313,  268,  367,  986,    1,  268]),\n",
              " array([ 449,   70,  964,    1,   50, 1341, 1678])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaqmERfSizej"
      },
      "source": [
        "FILTER_SIZES = list(range(1, 4)) # uni, bi and tri grams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH4n78QFi6Qz"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, max_filter_size):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.max_filter_size = max_filter_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Dataset(N={len(self.y)})>\"\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X = self.X[index]\n",
        "        y = self.y[index]\n",
        "\n",
        "        return [X, len(X), y]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        batch = np.array(batch, dtype=object)\n",
        "        X = batch[:, 0]\n",
        "        seq_lens = batch[:, 1]\n",
        "        y = np.stack(batch[:, 2], axis=0)\n",
        "\n",
        "        X = pad_sequences(sequences=X)\n",
        "\n",
        "        X = torch.LongTensor(X.astype(np.int32))\n",
        "        seq_lens = torch.LongTensor(seq_lens.astype(np.int32))\n",
        "        y = torch.LongTensor(y.astype(np.int32))\n",
        "\n",
        "        return X, seq_lens, y\n",
        "\n",
        "    def create_dataloader(self, batch_size, shuffle=False, drop_last=False):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            dataset=self, batch_size=batch_size, collate_fn=self.collate_fn,\n",
        "            shuffle=shuffle, drop_last=drop_last, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0-bUe7Dk7vJ",
        "outputId": "cdda9026-c8e6-4728-9d0e-10dfead73436"
      },
      "source": [
        "# Create datasets\n",
        "max_filter_size = max(FILTER_SIZES)\n",
        "train_dataset = Dataset(X=X_train, y=y_train, max_filter_size=max_filter_size)\n",
        "val_dataset = Dataset(X=X_val, y=y_val, max_filter_size=max_filter_size)\n",
        "test_dataset = Dataset(X=X_test, y=y_test, max_filter_size=max_filter_size)\n",
        "print (\"Datasets:\\n\"\n",
        "    f\"  Train dataset:{train_dataset.__str__()}\\n\"\n",
        "    f\"  Val dataset: {val_dataset.__str__()}\\n\"\n",
        "    f\"  Test dataset: {test_dataset.__str__()}\\n\"\n",
        "    \"Sample point:\\n\"\n",
        "    f\"  X: {train_dataset[0][0]}\\n\"\n",
        "    f\"  seq_len: {train_dataset[0][1]}\\n\"\n",
        "    f\"  y: {train_dataset[0][2]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datasets:\n",
            "  Train dataset:<Dataset(N=84000)>\n",
            "  Val dataset: <Dataset(N=18000)>\n",
            "  Test dataset: <Dataset(N=18000)>\n",
            "Sample point:\n",
            "  X: [   1 2038  963    1 3257]\n",
            "  seq_len: 5\n",
            "  y: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-cuzDAgk8-g",
        "outputId": "3775d1b6-a254-4095-98cf-6c2977862ce8"
      },
      "source": [
        "# Create dataloaders\n",
        "batch_size = 64\n",
        "train_dataloader = train_dataset.create_dataloader(\n",
        "    batch_size=batch_size)\n",
        "val_dataloader = val_dataset.create_dataloader(\n",
        "    batch_size=batch_size)\n",
        "test_dataloader = test_dataset.create_dataloader(\n",
        "    batch_size=batch_size)\n",
        "batch_X, batch_seq_lens, batch_y = next(iter(train_dataloader))\n",
        "print (\"Sample batch:\\n\"\n",
        "    f\"  X: {list(batch_X.size())}\\n\"\n",
        "    f\"  seq_lens: {list(batch_seq_lens.size())}\\n\"\n",
        "    f\"  y: {list(batch_y.size())}\\n\"\n",
        "    \"Sample point:\\n\"\n",
        "    f\"  X: {batch_X[0]}\\n\"\n",
        "    f\" seq_len: {batch_seq_lens[0]}\\n\"\n",
        "    f\"  y: {batch_y[0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample batch:\n",
            "  X: [64, 11]\n",
            "  seq_lens: [64]\n",
            "  y: [64]\n",
            "Sample point:\n",
            "  X: tensor([   1, 2038,  963,    1, 3257,    0,    0,    0,    0,    0,    0])\n",
            " seq_len: 5\n",
            "  y: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zS6Wbahl-DK"
      },
      "source": [
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7N3F1aZOlTWY"
      },
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, model, device, loss_fn=None, optimizer=None, scheduler=None):\n",
        "\n",
        "        # Set params\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "    def train_step(self, dataloader):\n",
        "        \"\"\"Train step.\"\"\"\n",
        "        # Set model to train mode\n",
        "        self.model.train()\n",
        "        loss = 0.0\n",
        "\n",
        "        # Iterate over train batches\n",
        "        for i, batch in enumerate(dataloader):\n",
        "\n",
        "            # Step\n",
        "            batch = [item.to(self.device) for item in batch]  # Set device\n",
        "            inputs, targets = batch[:-1], batch[-1]\n",
        "            self.optimizer.zero_grad()  # Reset gradients\n",
        "            z = self.model(inputs)  # Forward pass\n",
        "            J = self.loss_fn(z, targets)  # Define loss\n",
        "            J.backward()  # Backward pass\n",
        "            self.optimizer.step()  # Update weights\n",
        "\n",
        "            # Cumulative Metrics\n",
        "            loss += (J.detach().item() - loss) / (i + 1)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def eval_step(self, dataloader):\n",
        "        \"\"\"Validation or test step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        loss = 0.0\n",
        "        y_trues, y_probs = [], []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Step\n",
        "                batch = [item.to(self.device) for item in batch]  # Set device\n",
        "                inputs, y_true = batch[:-1], batch[-1]\n",
        "                z = self.model(inputs)  # Forward pass\n",
        "                J = self.loss_fn(z, y_true).item()\n",
        "\n",
        "                # Cumulative Metrics\n",
        "                loss += (J - loss) / (i + 1)\n",
        "\n",
        "                # Store outputs\n",
        "                y_prob = torch.sigmoid(z).cpu().numpy()\n",
        "                y_probs.extend(y_prob)\n",
        "                y_trues.extend(y_true.cpu().numpy())\n",
        "\n",
        "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
        "\n",
        "    def predict_step(self, dataloader):\n",
        "        \"\"\"Prediction step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        y_probs = []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Forward pass w/ inputs\n",
        "                inputs, targets = batch[:-1], batch[-1]\n",
        "                y_prob = self.model(inputs, apply_softmax=True)\n",
        "\n",
        "                # Store outputs\n",
        "                y_probs.extend(y_prob)\n",
        "\n",
        "        return np.vstack(y_probs)\n",
        "\n",
        "    def train(self, num_epochs, patience, train_dataloader, val_dataloader):\n",
        "        best_val_loss = np.inf\n",
        "        for epoch in range(num_epochs):\n",
        "            # Steps\n",
        "            train_loss = self.train_step(dataloader=train_dataloader)\n",
        "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
        "            self.scheduler.step(val_loss)\n",
        "\n",
        "            # Early stopping\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = self.model\n",
        "                _patience = patience  # reset _patience\n",
        "            else:\n",
        "                _patience -= 1\n",
        "            if not _patience:  # 0\n",
        "                print(\"Stopping early!\")\n",
        "                break\n",
        "\n",
        "            # Logging\n",
        "            print(\n",
        "                f\"Epoch: {epoch+1} | \"\n",
        "                f\"train_loss: {train_loss:.5f}, \"\n",
        "                f\"val_loss: {val_loss:.5f}, \"\n",
        "                f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
        "                f\"_patience: {_patience}\"\n",
        "            )\n",
        "        return best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blMnZ8FKmBKf"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "EMBEDDING_DIM = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3_SgsAjmWpf",
        "outputId": "58f176c5-4a59-49ab-d707-3b71f66e93e2"
      },
      "source": [
        "# Input\n",
        "sequence_size = 8 # words per input\n",
        "x = torch.rand((BATCH_SIZE, sequence_size, EMBEDDING_DIM))\n",
        "seq_lens = torch.randint(high=sequence_size, size=(1, BATCH_SIZE))\n",
        "print (x.shape)\n",
        "print (seq_lens.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 8, 100])\n",
            "torch.Size([1, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTRaxH27me9C"
      },
      "source": [
        "RNN_HIDDEN_DIM = 128\n",
        "DROPOUT_P = 0.1\n",
        "RNN_DROPOUT_P = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0uHArkimlBF",
        "outputId": "d6ff18c4-cbcb-4b78-fc16-4505f11c18ca"
      },
      "source": [
        "# Initialize hidden state\n",
        "hidden_t = torch.zeros((BATCH_SIZE, RNN_HIDDEN_DIM))\n",
        "print (hidden_t.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJo6cqXLmo2G",
        "outputId": "77faffde-d4f1-4bf1-cb3d-382d8f35be55"
      },
      "source": [
        "# Initialize RNN cell\n",
        "rnn_cell = nn.RNNCell(EMBEDDING_DIM, RNN_HIDDEN_DIM)\n",
        "print (rnn_cell)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNNCell(100, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmLbo-2Mm2us",
        "outputId": "9f3f34ac-d201-4bd0-9d60-0269e8ee2b2f"
      },
      "source": [
        "# Forward pass through RNN\n",
        "x = x.permute(1, 0, 2) # RNN needs batch_size to be at dim 1\n",
        "\n",
        "# Loop through the inputs time steps\n",
        "hiddens = []\n",
        "for t in range(sequence_size):\n",
        "    hidden_t = rnn_cell(x[t], hidden_t)\n",
        "    hiddens.append(hidden_t)\n",
        "hiddens = torch.stack(hiddens)\n",
        "hiddens = hiddens.permute(1, 0, 2) # bring batch_size back to dim 0\n",
        "print (hiddens.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 8, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNlLjV5LnSxX",
        "outputId": "42767b17-3a7e-4674-d6b3-ed137bdef01e"
      },
      "source": [
        "# We also could've used a more abstracted layer\n",
        "x = torch.rand((BATCH_SIZE, sequence_size, EMBEDDING_DIM))\n",
        "rnn = nn.RNN(EMBEDDING_DIM, RNN_HIDDEN_DIM, batch_first=True)\n",
        "out, h_n = rnn(x) # h_n is the last hidden state\n",
        "print (\"out: \", out.shape)\n",
        "print (\"h_n: \", h_n.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "out:  torch.Size([64, 8, 128])\n",
            "h_n:  torch.Size([1, 64, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGc1YoLAnfUu",
        "outputId": "3de17d53-82e7-480b-c061-d66ba88f4cdb"
      },
      "source": [
        "# The same tensors\n",
        "print (out[:,-1,:])\n",
        "print (h_n.squeeze(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.5106,  0.1550, -0.1367,  ..., -0.2666, -0.1516, -0.1995],\n",
            "        [-0.3352,  0.0989, -0.1955,  ..., -0.2617, -0.4543, -0.1326],\n",
            "        [-0.6425,  0.2002, -0.1804,  ..., -0.3815, -0.4300, -0.2057],\n",
            "        ...,\n",
            "        [-0.4790,  0.1860,  0.1568,  ..., -0.4702, -0.3543, -0.2998],\n",
            "        [-0.5783,  0.3212, -0.1418,  ...,  0.0799, -0.1650, -0.0704],\n",
            "        [-0.4951,  0.4392, -0.4269,  ..., -0.2001, -0.3974, -0.1463]],\n",
            "       grad_fn=<SliceBackward>)\n",
            "tensor([[-0.5106,  0.1550, -0.1367,  ..., -0.2666, -0.1516, -0.1995],\n",
            "        [-0.3352,  0.0989, -0.1955,  ..., -0.2617, -0.4543, -0.1326],\n",
            "        [-0.6425,  0.2002, -0.1804,  ..., -0.3815, -0.4300, -0.2057],\n",
            "        ...,\n",
            "        [-0.4790,  0.1860,  0.1568,  ..., -0.4702, -0.3543, -0.2998],\n",
            "        [-0.5783,  0.3212, -0.1418,  ...,  0.0799, -0.1650, -0.0704],\n",
            "        [-0.4951,  0.4392, -0.4269,  ..., -0.2001, -0.3974, -0.1463]],\n",
            "       grad_fn=<SqueezeBackward1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Sq0ukS1nwj3"
      },
      "source": [
        "def gather_last_relevant_hidden(hiddens, seq_lens):\n",
        "    \"\"\"Extract and collect the last relevant\n",
        "    hidden state based on the sequence length.\"\"\"\n",
        "    print(seq_lens)\n",
        "    seq_lens = seq_lens.long().detach().cpu().numpy() - 1\n",
        "    out = []\n",
        "    for batch_index, column_index in enumerate(seq_lens):\n",
        "        print(f\"column_index:{column_index}\")\n",
        "        print(f\"batch_index:{batch_index}\")\n",
        "        out.append(hiddens[batch_index, column_index])\n",
        "    return torch.stack(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceKEXtlwoPMD",
        "outputId": "05695ab4-f26b-41f2-f034-ed5b1046f6a0"
      },
      "source": [
        "# Get the last relevant hidden state\n",
        "gather_last_relevant_hidden(hiddens=out, seq_lens=seq_lens).squeeze(0).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 4, 1, 6, 1, 0, 0, 6, 6, 1, 1, 6, 5, 2, 2, 2, 2, 0, 0, 3, 3, 4, 4, 0,\n",
            "         3, 0, 4, 2, 3, 4, 4, 7, 4, 3, 1, 4, 1, 0, 3, 7, 1, 6, 5, 7, 4, 6, 5, 4,\n",
            "         0, 3, 2, 2, 2, 1, 1, 4, 0, 3, 3, 5, 5, 0, 4, 1]])\n",
            "column_index:[ 0  3  0  5  0 -1 -1  5  5  0  0  5  4  1  1  1  1 -1 -1  2  2  3  3 -1\n",
            "  2 -1  3  1  2  3  3  6  3  2  0  3  0 -1  2  6  0  5  4  6  3  5  4  3\n",
            " -1  2  1  1  1  0  0  3 -1  2  2  4  4 -1  3  0]\n",
            "batch_index:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK5eZMKMoQ7J"
      },
      "source": [
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6J8WbXbssNp"
      },
      "source": [
        "HIDDEN_DIM = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ox9S1f9bstqm"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, vocab_size, rnn_hidden_dim,\n",
        "                 hidden_dim, dropout_p, num_classes, padding_idx=0):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        # Initialize embeddings\n",
        "        self.embeddings = nn.Embedding(\n",
        "            embedding_dim=embedding_dim, num_embeddings=vocab_size,\n",
        "            padding_idx=padding_idx)\n",
        "\n",
        "        # RNN\n",
        "        self.rnn = nn.RNN(embedding_dim, rnn_hidden_dim, batch_first=True)\n",
        "\n",
        "        # FC weights\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc1 = nn.Linear(rnn_hidden_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, inputs, apply_softmax=False):\n",
        "        # Embed\n",
        "        x_in, seq_lens = inputs\n",
        "        x_in = self.embeddings(x_in)\n",
        "\n",
        "        # Rnn outputs\n",
        "        out, h_n = self.rnn(x_in)\n",
        "        z = gather_last_relevant_hidden(hiddens=out, seq_lens=seq_lens)\n",
        "        print(z)\n",
        "        print(h_n)\n",
        "        sys.exit(0)\n",
        "\n",
        "        # FC layers\n",
        "        z = self.fc1(z)\n",
        "        z = self.dropout(z)\n",
        "        y_pred = self.fc2(z)\n",
        "\n",
        "        if apply_softmax:\n",
        "            y_pred = F.softmax(y_pred, dim=1)\n",
        "        return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVk3oifTsvSO",
        "outputId": "715a34e0-bb34-47c4-ba25-5bc233504a00"
      },
      "source": [
        "# Simple RNN cell\n",
        "model = RNN(\n",
        "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\n",
        "    rnn_hidden_dim=RNN_HIDDEN_DIM, hidden_dim=HIDDEN_DIM,\n",
        "    dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)\n",
        "model = model.to(device) # set device\n",
        "print (model.named_parameters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.named_parameters of RNN(\n",
            "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
            "  (rnn): RNN(100, 128, batch_first=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fc1): Linear(in_features=128, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXSEYiNOtkR6"
      },
      "source": [
        "from torch.optim import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haLpJJroto5l"
      },
      "source": [
        "NUM_LAYERS = 1\n",
        "LEARNING_RATE = 1e-4\n",
        "PATIENCE = 10\n",
        "NUM_EPOCHS = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g-q00kqwb_k"
      },
      "source": [
        "# Define Loss\n",
        "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xsaM25OweWM"
      },
      "source": [
        "# Define optimizer & scheduler\n",
        "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.1, patience=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiYSIaF8wf6d"
      },
      "source": [
        "# Trainer module\n",
        "trainer = Trainer(\n",
        "    model=model, device=device, loss_fn=loss_fn,\n",
        "    optimizer=optimizer, scheduler=scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "R_mmwqzDwg8V",
        "outputId": "0071b8e6-a63d-4b6c-ae1e-f31c46b6d12c"
      },
      "source": [
        "# Train\n",
        "best_model = trainer.train(\n",
        "    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.6144,  0.1413,  0.2809,  ...,  0.4665,  0.5974,  0.2586],\n",
            "        [-0.4076,  0.2020, -0.0709,  ...,  0.4942, -0.4969,  0.1077],\n",
            "        [ 0.1707,  0.6015,  0.0212,  ..., -0.1275,  0.3425, -0.1844],\n",
            "        ...,\n",
            "        [ 0.1270,  0.6666,  0.8198,  ...,  0.1013, -0.1388,  0.6960],\n",
            "        [ 0.1975, -0.4622, -0.6726,  ...,  0.1162, -0.5428, -0.8140],\n",
            "        [-0.3054,  0.2000, -0.8098,  ...,  0.7265, -0.1572, -0.6151]],\n",
            "       grad_fn=<StackBackward>)\n",
            "tensor([[[-1.3210e-01,  1.5695e-01, -2.5950e-02,  ...,  9.4291e-02,\n",
            "          -1.2255e-01, -1.6328e-02],\n",
            "         [-1.0918e-01,  1.2790e-01, -6.0527e-02,  ...,  8.4810e-02,\n",
            "          -1.4664e-01, -4.0609e-03],\n",
            "         [-1.8552e-02,  7.4403e-02, -6.6307e-02,  ...,  2.1516e-01,\n",
            "          -1.7411e-01,  1.2210e-02],\n",
            "         ...,\n",
            "         [-1.2856e-01,  1.2487e-01, -1.1161e-02,  ...,  5.1288e-02,\n",
            "          -1.7624e-01, -5.5097e-06],\n",
            "         [-1.1352e-01,  1.0907e-01, -6.2950e-02,  ...,  1.1151e-01,\n",
            "          -9.5556e-02,  1.3124e-03],\n",
            "         [-1.3936e-01,  1.4508e-01, -2.5867e-02,  ...,  7.9813e-02,\n",
            "          -1.1788e-01, -1.1898e-02]]], grad_fn=<StackBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-MYZZPuwkDr"
      },
      "source": [
        "import json\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CGncK3bxukt"
      },
      "source": [
        "def get_metrics(y_true, y_pred, classes):\n",
        "    \"\"\"Per-class performance metrics.\"\"\"\n",
        "    # Performance\n",
        "    performance = {\"overall\": {}, \"class\": {}}\n",
        "\n",
        "    # Overall performance\n",
        "    metrics = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "    performance[\"overall\"][\"precision\"] = metrics[0]\n",
        "    performance[\"overall\"][\"recall\"] = metrics[1]\n",
        "    performance[\"overall\"][\"f1\"] = metrics[2]\n",
        "    performance[\"overall\"][\"num_samples\"] = np.float64(len(y_true))\n",
        "\n",
        "    # Per-class performance\n",
        "    metrics = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
        "    for i in range(len(classes)):\n",
        "        performance[\"class\"][classes[i]] = {\n",
        "            \"precision\": metrics[0][i],\n",
        "            \"recall\": metrics[1][i],\n",
        "            \"f1\": metrics[2][i],\n",
        "            \"num_samples\": np.float64(metrics[3][i]),\n",
        "        }\n",
        "\n",
        "    return performance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqPB8X1mxv2m"
      },
      "source": [
        "# Get predictions\n",
        "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
        "y_pred = np.argmax(y_prob, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yw8-dQuuxxTy",
        "outputId": "8437347c-4139-4766-a328-ef48e0ff86d2"
      },
      "source": [
        "# Determine performance\n",
        "performance = get_metrics(\n",
        "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
        "print (json.dumps(performance['overall'], indent=2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"precision\": 0.535014901521111,\n",
            "  \"recall\": 0.5327222222222222,\n",
            "  \"f1\": 0.5318451846429071,\n",
            "  \"num_samples\": 18000.0\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqIHh8lYxypB",
        "outputId": "61c14dc3-751e-4ca2-c215-d0ca03f5258c"
      },
      "source": [
        "# Input\n",
        "sequence_size = 8 # words per input\n",
        "x = torch.rand((BATCH_SIZE, sequence_size, EMBEDDING_DIM))\n",
        "print (x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 8, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_UelaNjx5OR"
      },
      "source": [
        "# GRU\n",
        "gru = nn.GRU(input_size=EMBEDDING_DIM, hidden_size=RNN_HIDDEN_DIM, batch_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrKhCXetx6z8",
        "outputId": "b61fbad3-5539-4c75-a772-f81f9922a7f8"
      },
      "source": [
        "# Forward pass\n",
        "out, h_n = gru(x)\n",
        "print (f\"out: {out.shape}\")\n",
        "print (f\"h_n: {h_n.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "out: torch.Size([64, 8, 128])\n",
            "h_n: torch.Size([1, 64, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtxPWD0nx85U"
      },
      "source": [
        "# GRU\n",
        "gru = nn.GRU(input_size=EMBEDDING_DIM, hidden_size=RNN_HIDDEN_DIM,\n",
        "             batch_first=True, bidirectional=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn1Cc6REyBvj",
        "outputId": "eaec0f7f-820e-456c-cdfe-e754cbe2bebb"
      },
      "source": [
        "# Forward pass\n",
        "out, h_n = gru(x)\n",
        "print (f\"out: {out.shape}\")\n",
        "print (f\"h_n: {h_n.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "out: torch.Size([64, 8, 256])\n",
            "h_n: torch.Size([2, 64, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LLDhCTYyD4L"
      },
      "source": [
        "class GRU(nn.Module):\n",
        "    def __init__(self, embedding_dim, vocab_size, rnn_hidden_dim,\n",
        "                 hidden_dim, dropout_p, num_classes, padding_idx=0):\n",
        "        super(GRU, self).__init__()\n",
        "\n",
        "        # Initialize embeddings\n",
        "        self.embeddings = nn.Embedding(embedding_dim=embedding_dim,\n",
        "                                       num_embeddings=vocab_size,\n",
        "                                       padding_idx=padding_idx)\n",
        "\n",
        "        # RNN\n",
        "        self.rnn = nn.GRU(embedding_dim, rnn_hidden_dim,\n",
        "                          batch_first=True, bidirectional=True)\n",
        "\n",
        "        # FC weights\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc1 = nn.Linear(rnn_hidden_dim*2, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, inputs, apply_softmax=False):\n",
        "        # Embed\n",
        "        x_in, seq_lens = inputs\n",
        "        x_in = self.embeddings(x_in)\n",
        "\n",
        "        # Rnn outputs\n",
        "        out, h_n = self.rnn(x_in)\n",
        "        z = gather_last_relevant_hidden(hiddens=out, seq_lens=seq_lens)\n",
        "        print(z)\n",
        "        print(h_n)\n",
        "        sys.exit(0)\n",
        "        # FC layers\n",
        "        z = self.fc1(z)\n",
        "        z = self.dropout(z)\n",
        "        y_pred = self.fc2(z)\n",
        "\n",
        "        if apply_softmax:\n",
        "            y_pred = F.softmax(y_pred, dim=1)\n",
        "        return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPIT2QoWy0ET",
        "outputId": "f1794cc6-aa50-423d-c6b5-fb764c123a62"
      },
      "source": [
        "# Simple RNN cell\n",
        "model = GRU(\n",
        "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\n",
        "    rnn_hidden_dim=RNN_HIDDEN_DIM, hidden_dim=HIDDEN_DIM,\n",
        "    dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)\n",
        "model = model.to(device) # set device\n",
        "print (model.named_parameters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.named_parameters of GRU(\n",
            "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
            "  (rnn): GRU(100, 128, batch_first=True, bidirectional=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fc1): Linear(in_features=256, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LGvWu_-ylDM"
      },
      "source": [
        "# Define Loss\n",
        "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
        "loss = nn.CrossEntropyLoss(weight=class_weights_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0U-bf2wymbC"
      },
      "source": [
        "# Define optimizer & scheduler\n",
        "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.1, patience=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wduLYA6-yn4x"
      },
      "source": [
        "# Trainer module\n",
        "trainer = Trainer(\n",
        "    model=model, device=device, loss_fn=loss,\n",
        "    optimizer=optimizer, scheduler=scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "es3iiXRHyppZ",
        "outputId": "b722d21b-d013-4b11-f8e2-0765f75a21de"
      },
      "source": [
        "# Train\n",
        "best_model = trainer.train(\n",
        "    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.1076,  0.0203,  0.4070,  ..., -0.2434,  0.4046, -0.2906],\n",
            "        [-0.0482, -0.3683,  0.0157,  ..., -0.1171,  0.0091, -0.1434],\n",
            "        [-0.0730, -0.1345,  0.5942,  ..., -0.2555,  0.0346, -0.1389],\n",
            "        ...,\n",
            "        [ 0.2085,  0.0236,  0.2493,  ...,  0.1295, -0.0073, -0.3213],\n",
            "        [-0.1409,  0.2499,  0.3724,  ..., -0.0078, -0.0047, -0.1569],\n",
            "        [ 0.2241, -0.2549,  0.4227,  ...,  0.0763,  0.2559, -0.0822]],\n",
            "       grad_fn=<StackBackward>)\n",
            "tensor([[[-0.0306, -0.0049, -0.0881,  ..., -0.0214, -0.1131,  0.1141],\n",
            "         [-0.0378, -0.0281, -0.1002,  ..., -0.0591, -0.0940,  0.0512],\n",
            "         [-0.0304, -0.0214, -0.0334,  ..., -0.0550, -0.0926,  0.0420],\n",
            "         ...,\n",
            "         [-0.0232,  0.0061, -0.0393,  ..., -0.0387, -0.1295,  0.0571],\n",
            "         [-0.0530, -0.0171, -0.0845,  ..., -0.0426, -0.1165,  0.0976],\n",
            "         [-0.0521, -0.0198, -0.1019,  ..., -0.0458, -0.0954,  0.0683]],\n",
            "\n",
            "        [[-0.1302, -0.4508, -0.1086,  ..., -0.0669,  0.0109, -0.0557],\n",
            "         [ 0.2096,  0.3604, -0.0564,  ...,  0.2066, -0.3234, -0.0275],\n",
            "         [-0.1859, -0.2441, -0.0380,  ..., -0.0868,  0.0725, -0.2897],\n",
            "         ...,\n",
            "         [-0.0659,  0.1870, -0.1080,  ..., -0.4636,  0.0841,  0.0583],\n",
            "         [ 0.0537, -0.4127, -0.0596,  ...,  0.0353,  0.1223,  0.0622],\n",
            "         [-0.2979, -0.5503, -0.1282,  ..., -0.5677, -0.1582, -0.2438]]],\n",
            "       grad_fn=<StackBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk9weNtNyqxP"
      },
      "source": [
        "#Testing cells"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftCtw6vd0-P_"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De36LWw81CkO"
      },
      "source": [
        "def gather_last_relevant_hidden(hiddens, seq_lens):\n",
        "    \"\"\"Extract and collect the last relevant\n",
        "    hidden state based on the sequence length.\"\"\"\n",
        "    seq_lens = seq_lens.long().detach().cpu().numpy() - 1\n",
        "    out = []\n",
        "    for batch_index, column_index in enumerate(seq_lens):\n",
        "        out.append(hiddens[batch_index, column_index])\n",
        "    return torch.stack(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOmBsqwj1Eze"
      },
      "source": [
        "BATCH_SIZE = 2\n",
        "EMBEDDING_DIM = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnW0BzSg1JhH",
        "outputId": "c224f1d6-4ef4-4de6-a7dd-77c8b9dbc8ab"
      },
      "source": [
        "# Input\n",
        "sequence_size = 5 # words per input\n",
        "x = torch.rand((BATCH_SIZE, sequence_size, EMBEDDING_DIM))\n",
        "seq_lens = torch.randint(high=sequence_size, size=(1, BATCH_SIZE))\n",
        "print (x.shape)\n",
        "print (seq_lens.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 5, 4])\n",
            "torch.Size([1, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPEcg5ry1MJX",
        "outputId": "f309cf10-f98d-46a7-ab0c-faf228de1a26"
      },
      "source": [
        "seq_lens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHnqWLeM1Pzo",
        "outputId": "dc4468c8-b468-4fa3-f3bd-f1d75d96f8b6"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.3730, 0.8467, 0.4450, 0.9095],\n",
              "         [0.0148, 0.7017, 0.3694, 0.6783],\n",
              "         [0.5956, 0.6080, 0.3029, 0.9555],\n",
              "         [0.7813, 0.1294, 0.5745, 0.1748],\n",
              "         [0.5227, 0.9340, 0.7143, 0.7911]],\n",
              "\n",
              "        [[0.5970, 0.3269, 0.2179, 0.8938],\n",
              "         [0.0399, 0.7193, 0.7832, 0.2968],\n",
              "         [0.1224, 0.7740, 0.2536, 0.1784],\n",
              "         [0.0558, 0.6388, 0.8998, 0.9598],\n",
              "         [0.2116, 0.9886, 0.9557, 0.8035]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP0iigkc1QyP"
      },
      "source": [
        "RNN_HIDDEN_DIM = 5\n",
        "DROPOUT_P = 0.1\n",
        "RNN_DROPOUT_P = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G3FqU2N1g49",
        "outputId": "6169dd49-2a01-4bab-e8c0-23b945e4db09"
      },
      "source": [
        "# Initialize hidden state\n",
        "hidden_t = torch.zeros((BATCH_SIZE, RNN_HIDDEN_DIM))\n",
        "print (hidden_t.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lopzL-l1imB",
        "outputId": "4658926a-e479-4438-da67-af7fbb8b9601"
      },
      "source": [
        "# We also could've used a more abstracted layer\n",
        "# x = torch.rand((BATCH_SIZE, sequence_size, EMBEDDING_DIM))\n",
        "rnn = nn.RNN(EMBEDDING_DIM, RNN_HIDDEN_DIM, batch_first=True)\n",
        "out, h_n = rnn(x) # h_n is the last hidden state\n",
        "print (\"out: \", out.shape)\n",
        "print (\"h_n: \", h_n.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "out:  torch.Size([2, 5, 5])\n",
            "h_n:  torch.Size([1, 2, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_uaWy3h1r21"
      },
      "source": [
        "# Get the last relevant hidden state\n",
        "z = gather_last_relevant_hidden(hiddens=out, seq_lens=seq_lens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsQgLTXP12ba",
        "outputId": "804a63a6-a428-4c89-9fc1-10413a908ef6"
      },
      "source": [
        "z"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.4699, -0.2811,  0.3740, -0.1991, -0.4477],\n",
              "         [-0.4313, -0.1389,  0.4519,  0.0634, -0.3792]]],\n",
              "       grad_fn=<StackBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEWA_O9F2XRg",
        "outputId": "b9a4e997-443a-4548-afb8-bd37e53c0b30"
      },
      "source": [
        "out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.4699, -0.2811,  0.3740, -0.1991, -0.4477],\n",
              "         [-0.4313, -0.1389,  0.4519,  0.0634, -0.3792],\n",
              "         [-0.3287, -0.2803,  0.5780, -0.0395, -0.2967],\n",
              "         [-0.3167, -0.3641,  0.6104, -0.5065, -0.2157],\n",
              "         [-0.4896, -0.3371,  0.5245, -0.2444, -0.6252]],\n",
              "\n",
              "        [[-0.3406, -0.3013,  0.5843, -0.3599, -0.2522],\n",
              "         [-0.4481, -0.2736,  0.3602, -0.2044, -0.5484],\n",
              "         [-0.5782, -0.0377,  0.3846, -0.0162, -0.2145],\n",
              "         [-0.1840, -0.4854,  0.2840,  0.0108, -0.5652],\n",
              "         [-0.5505, -0.2334,  0.4232, -0.1274, -0.5333]]],\n",
              "       grad_fn=<TransposeBackward1>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3fJpeoD2Y6I",
        "outputId": "393f9f3d-5e6d-4ebb-fe53-4f9813d7a30b"
      },
      "source": [
        "h_n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.4896, -0.3371,  0.5245, -0.2444, -0.6252],\n",
              "         [-0.5505, -0.2334,  0.4232, -0.1274, -0.5333]]],\n",
              "       grad_fn=<StackBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LexDB2FV17Zw",
        "outputId": "c6f9f526-e270-446e-8945-db5ff4993e10"
      },
      "source": [
        "z.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHV54DPJ2QS8",
        "outputId": "04c592ca-d0dc-4778-f153-6aaa0caf7bec"
      },
      "source": [
        "h_n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.3996, -0.4355,  0.0680,  0.2319, -0.6096, -0.3701,  0.0888,\n",
              "          -0.1354],\n",
              "         [-0.6693, -0.5435,  0.2675,  0.0390, -0.3204, -0.2002,  0.4912,\n",
              "          -0.0896],\n",
              "         [-0.5305, -0.5099,  0.2141,  0.1776, -0.5199, -0.2458,  0.3208,\n",
              "          -0.0570],\n",
              "         [-0.3000, -0.5704,  0.1442, -0.0658, -0.5751, -0.5448,  0.2178,\n",
              "           0.2336]]], grad_fn=<StackBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ2Ky28b2RtU",
        "outputId": "76580ef0-8095-4b10-b4fb-d55a6cb4213c"
      },
      "source": [
        "h_n.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRUFhxSZ2Tew"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}