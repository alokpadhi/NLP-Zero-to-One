{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word_Embedding_Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqrsnDXKhtqV",
        "outputId": "b1b46d2d-3748-465d-d37f-f8f0bcf8e98b"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import numpy as np\n",
        "import re\n",
        "import urllib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWZS68RtiaOP"
      },
      "source": [
        "SEED = 1234"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9F2qD3KXikMx"
      },
      "source": [
        "np.random.seed(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEwSUKDZimZo",
        "outputId": "c0f6b8be-4425-4250-8d08-3f977d6ce773"
      },
      "source": [
        "# Split text into sentences\n",
        "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "book = urllib.request.urlopen(url=\"https://raw.githubusercontent.com/GokuMohandas/MadeWithML/main/datasets/harrypotter.txt\")\n",
        "sentences = tokenizer.tokenize(str(book.read()))\n",
        "print (f\"{len(sentences)} sentences\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12443 sentences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMT1pwK9itLJ"
      },
      "source": [
        "def preprocess(text):\n",
        "    \"\"\"Conditional preprocessing on our text.\"\"\"\n",
        "    # Lower\n",
        "    text = text.lower()\n",
        "\n",
        "    # Spacing and filters\n",
        "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\n",
        "    text = re.sub('[^A-Za-z0-9]+', ' ', text) # remove non alphanumeric chars\n",
        "    text = re.sub(' +', ' ', text)  # remove multiple spaces\n",
        "    text = text.strip()\n",
        "\n",
        "    # Separate into word tokens\n",
        "    text = text.split(\" \")\n",
        "\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkRhQ61Tiva_",
        "outputId": "c907f407-8308-407a-d2f5-19d243e42e4d"
      },
      "source": [
        "# Preprocess sentences\n",
        "print (sentences[11])\n",
        "sentences = [preprocess(sentence) for sentence in sentences]\n",
        "print (sentences[11])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snape nodded, but did not elaborate.\n",
            "['snape', 'nodded', 'but', 'did', 'not', 'elaborate']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXkvycKfixmJ"
      },
      "source": [
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35gMN89gjWqG"
      },
      "source": [
        "EMBEDDING_DIM = 100\n",
        "WINDOW = 5\n",
        "MIN_COUNT = 3\n",
        "SKIP_GRAM = 1\n",
        "NEGATIVE_SAMPLING = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOyzdEMcjgyq",
        "outputId": "97abb8f0-2075-4366-85f7-6876d11090ae"
      },
      "source": [
        "# Super fast because of optimized C code under the hood\n",
        "w2v = Word2Vec(\n",
        "    sentences=sentences, size=EMBEDDING_DIM,\n",
        "    window=WINDOW, min_count=MIN_COUNT,\n",
        "    sg=SKIP_GRAM, negative=NEGATIVE_SAMPLING)\n",
        "print (w2v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=4937, size=100, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf-hL7Vhjnmb",
        "outputId": "ceb0bb7f-75c5-473b-b24f-d85e24c1986d"
      },
      "source": [
        "# Vector for each word\n",
        "w2v.wv.get_vector(\"potter\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.16878249,  0.0646591 , -0.09511224,  0.1313778 ,  0.37642577,\n",
              "        0.0133142 ,  0.22131741, -0.20939402, -0.14857376,  0.10234828,\n",
              "        0.7035531 , -0.30785272, -0.2395543 , -0.30282462,  0.06618554,\n",
              "        0.19479343,  0.11968745,  0.26677617, -0.17538998,  0.13266644,\n",
              "        0.47685987,  0.25788087,  0.18457626,  0.02747607,  0.04406137,\n",
              "       -0.26546204, -0.11882149,  0.13603602,  0.34363922, -0.15364629,\n",
              "        0.0368128 ,  0.20160817, -0.29112533, -0.23923992,  0.02422284,\n",
              "       -0.10648021,  0.3062819 , -0.06218803, -0.20987706, -0.49168438,\n",
              "        0.12856369, -0.16996889, -0.08725958, -0.17050624, -0.04325509,\n",
              "        0.17237669, -0.25499368,  0.04982383, -0.21869177,  0.65881866,\n",
              "        0.30661413, -0.04850129, -0.42801064, -0.29383826, -0.21269658,\n",
              "        0.28379595, -0.31561178, -0.1802317 ,  0.21647519,  0.3295883 ,\n",
              "        0.26976636,  0.27238932, -0.30126682, -0.09117985, -0.29378748,\n",
              "        0.41141877, -0.07646773, -0.31833187,  0.02232784, -0.20459971,\n",
              "       -0.03116087, -0.58178264,  0.01903126, -0.1968791 , -0.29596695,\n",
              "       -0.00661719, -0.05140947,  0.14134549, -0.3141347 , -0.04226614,\n",
              "       -0.2307046 ,  0.07754862, -0.2707954 , -0.0403006 ,  0.14626645,\n",
              "       -0.02603203, -0.15403256,  0.1719543 ,  0.2744435 ,  0.2591648 ,\n",
              "       -0.07855675, -0.35533437, -0.3148236 , -0.01641574,  0.03129493,\n",
              "        0.00885342, -0.03264654,  0.13433209, -0.43832552,  0.19308034],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYR35EZYjz_Z",
        "outputId": "8f790f67-c72d-4a9e-8448-7555e6914b28"
      },
      "source": [
        "# Get nearest neighbors (excluding itself)\n",
        "w2v.wv.most_similar(positive=\"scar\", topn=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('forehead', 0.9390738606452942),\n",
              " ('pain', 0.9266612529754639),\n",
              " ('mouth', 0.909773588180542),\n",
              " ('heart', 0.9070560932159424),\n",
              " ('prickling', 0.9056209325790405)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fBMbG-xj3Kx"
      },
      "source": [
        "# Saving and loading\n",
        "w2v.wv.save_word2vec_format('model.bin', binary=True)\n",
        "w2v = KeyedVectors.load_word2vec_format('model.bin', binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSXiu4ofj5kY"
      },
      "source": [
        "from gensim.models import FastText"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-TXZ7-ikFHJ",
        "outputId": "3fbaa0c9-4ea1-4f73-8fb2-e2b6395ee9b1"
      },
      "source": [
        "# Super fast because of optimized C code under the hood\n",
        "ft = FastText(sentences=sentences, size=EMBEDDING_DIM,\n",
        "              window=WINDOW, min_count=MIN_COUNT,\n",
        "              sg=SKIP_GRAM, negative=NEGATIVE_SAMPLING)\n",
        "print (ft)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FastText(vocab=4937, size=100, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWObWZKPkG9J",
        "outputId": "19e2a69c-b40f-42b0-d511-b2950f0d1674"
      },
      "source": [
        "try:\n",
        "    w2v.wv.most_similar(positive=\"scarring\", topn=5)\n",
        "except:\n",
        "    print(\"Word is not present in the Vocab\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word is not present in the Vocab\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_X1xgk-IkMx5",
        "outputId": "33bf69b3-a087-4cd3-d8df-37a0592a270f"
      },
      "source": [
        "# FastText will use n-grams to embed an OOV word\n",
        "ft.wv.most_similar(positive=\"scarring\", topn=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('shimmering', 0.9770721793174744),\n",
              " ('trembling', 0.9754676818847656),\n",
              " ('brandishing', 0.9750562906265259),\n",
              " ('scattering', 0.9741926193237305),\n",
              " ('clattering', 0.9731274843215942)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT07ZJMCkc9n"
      },
      "source": [
        "# Save and loading\n",
        "ft.wv.save('model.bin')\n",
        "ft = KeyedVectors.load('model.bin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-iH7tbUkgn_"
      },
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from urllib.request import urlopen\n",
        "from zipfile import ZipFile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MfEn6KDk8Yz"
      },
      "source": [
        "# Arguments\n",
        "EMBEDDING_DIM = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf3JwseVk9_D"
      },
      "source": [
        "def plot_embeddings(words, embeddings, pca_results):\n",
        "    for word in words:\n",
        "        index = embeddings.index2word.index(word)\n",
        "        plt.scatter(pca_results[index, 0], pca_results[index, 1])\n",
        "        plt.annotate(word, xy=(pca_results[index, 0], pca_results[index, 1]))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwVpUqL9laYq",
        "outputId": "e69ec97b-80a5-47c0-9886-b7d60b012207"
      },
      "source": [
        "# Unzip the file (may take ~3-5 minutes)\n",
        "resp = urlopen('http://nlp.stanford.edu/data/glove.6B.zip')\n",
        "zipfile = ZipFile(BytesIO(resp.read()))\n",
        "zipfile.namelist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['glove.6B.50d.txt',\n",
              " 'glove.6B.100d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.6B.300d.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YOochdEglb_o",
        "outputId": "228edead-52ea-41b6-9d0f-5dfacc51e3e7"
      },
      "source": [
        "# Write embeddings to file\n",
        "embeddings_file = 'glove.6B.{0}d.txt'.format(EMBEDDING_DIM)\n",
        "zipfile.extract(embeddings_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/glove.6B.100d.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5nZZDF1mPaQ",
        "outputId": "d7be3ccd-9f3a-468e-ef9f-4d2528880c84"
      },
      "source": [
        "# Preview of the GloVe embeddings file\n",
        "with open(embeddings_file, 'r') as fp:\n",
        "    line = next(fp)\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    embedding = np.asarray(values[1:], dtype='float32')\n",
        "    print (f\"word: {word}\")\n",
        "    print (f\"embedding:\\n{embedding}\")\n",
        "    print (f\"embedding dim: {len(embedding)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word: the\n",
            "embedding:\n",
            "[-0.038194 -0.24487   0.72812  -0.39961   0.083172  0.043953 -0.39141\n",
            "  0.3344   -0.57545   0.087459  0.28787  -0.06731   0.30906  -0.26384\n",
            " -0.13231  -0.20757   0.33395  -0.33848  -0.31743  -0.48336   0.1464\n",
            " -0.37304   0.34577   0.052041  0.44946  -0.46971   0.02628  -0.54155\n",
            " -0.15518  -0.14107  -0.039722  0.28277   0.14393   0.23464  -0.31021\n",
            "  0.086173  0.20397   0.52624   0.17164  -0.082378 -0.71787  -0.41531\n",
            "  0.20335  -0.12763   0.41367   0.55187   0.57908  -0.33477  -0.36559\n",
            " -0.54857  -0.062892  0.26584   0.30205   0.99775  -0.80481  -3.0243\n",
            "  0.01254  -0.36942   2.2167    0.72201  -0.24978   0.92136   0.034514\n",
            "  0.46745   1.1079   -0.19358  -0.074575  0.23353  -0.052062 -0.22044\n",
            "  0.057162 -0.15806  -0.30798  -0.41625   0.37972   0.15006  -0.53212\n",
            " -0.2055   -1.2526    0.071624  0.70565   0.49744  -0.42063   0.26148\n",
            " -1.538    -0.30223  -0.073438 -0.28312   0.37104  -0.25217   0.016215\n",
            " -0.017099 -0.38984   0.87424  -0.72569  -0.51058  -0.52028  -0.1459\n",
            "  0.8278    0.27062 ]\n",
            "embedding dim: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofFMFL3hmdQ_",
        "outputId": "97b69864-2f16-40a7-effb-81ac9b025200"
      },
      "source": [
        "# Save GloVe embeddings to local directory in word2vec format\n",
        "word2vec_output_file = '{0}.word2vec'.format(embeddings_file)\n",
        "glove2word2vec(embeddings_file, word2vec_output_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5MWCOE1nBMV"
      },
      "source": [
        "# Load embeddings (may take a minute)\n",
        "glove = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1oSURutnIpC",
        "outputId": "912d7ac3-02c4-4048-e7a9-a083b3d54065"
      },
      "source": [
        "# (king - man) + woman = ?\n",
        "glove.most_similar(positive=['woman', 'king'], negative=['man'], topn=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7698541283607483),\n",
              " ('monarch', 0.6843380928039551),\n",
              " ('throne', 0.6755735874176025),\n",
              " ('daughter', 0.6594556570053101),\n",
              " ('princess', 0.6520534753799438)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRKIFC0JnOIr",
        "outputId": "8b6177d9-a27f-4923-c653-2d82f7bff20c"
      },
      "source": [
        "# Get nearest neighbors (exlcusing itself)\n",
        "glove.wv.most_similar(positive=\"goku\", topn=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('gohan', 0.7246542572975159),\n",
              " ('bulma', 0.6497020125389099),\n",
              " ('raistlin', 0.6443604230880737),\n",
              " ('skaar', 0.6316742897033691),\n",
              " ('guybrush', 0.6231324672698975)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gxb-34GnQai",
        "outputId": "863cd93d-a6a0-4800-e13a-8f0874d586e2"
      },
      "source": [
        "# Reduce dimensionality for plotting\n",
        "X = glove[glove.wv.vocab]\n",
        "pca = PCA(n_components=2)\n",
        "pca_results = pca.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Armp6wkmnWI7",
        "outputId": "38fecfd8-fbb4-4941-dd9e-7f88a9086332"
      },
      "source": [
        "# Visualize\n",
        "plot_embeddings(\n",
        "    words=[\"king\", \"queen\", \"man\", \"woman\"], embeddings=glove,\n",
        "    pca_results=pca_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI0Bk1E7nYnQ",
        "outputId": "7aeaafab-05cd-40af-8e50-24e8b0b08527"
      },
      "source": [
        "# Bias in embeddings\n",
        "glove.most_similar(positive=['woman', 'doctor'], negative=['man'], topn=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('nurse', 0.7735227346420288),\n",
              " ('physician', 0.7189429998397827),\n",
              " ('doctors', 0.6824328303337097),\n",
              " ('patient', 0.6750682592391968),\n",
              " ('dentist', 0.6726033687591553)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t8mZMy3nff9"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxECOdvsoSTC"
      },
      "source": [
        "SEED = 1234"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJlOH36roUmy"
      },
      "source": [
        "def set_seeds(seed=1234):\n",
        "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) # multi-GPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M329cdx1oV46",
        "outputId": "7f663182-7b66-434e-c286-34b15eb56c8f"
      },
      "source": [
        "# Set device\n",
        "cuda = True\n",
        "device = torch.device('cuda' if (\n",
        "    torch.cuda.is_available() and cuda) else 'cpu')\n",
        "torch.set_default_tensor_type('torch.FloatTensor')\n",
        "if device.type == 'cuda':\n",
        "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "print (device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "A9xTbfuCoXK5",
        "outputId": "e2fb039e-ee54-44b8-dd38-8130475a60c2"
      },
      "source": [
        "# Load data\n",
        "url = \"https://raw.githubusercontent.com/GokuMohandas/MadeWithML/main/datasets/news.csv\"\n",
        "df = pd.read_csv(url, header=0) # load\n",
        "df = df.sample(frac=1).reset_index(drop=True) # shuffle\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GE lights up as its sales explode</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bears #39; quarterback situation is not pretty</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Labour MPs urge Iraq troop vote</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Russian soldiers kill two, take hostages</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Proposal Would Require Independent Board Major...</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  category\n",
              "0                  GE lights up as its sales explode  Business\n",
              "1     Bears #39; quarterback situation is not pretty    Sports\n",
              "2                    Labour MPs urge Iraq troop vote     World\n",
              "3           Russian soldiers kill two, take hostages     World\n",
              "4  Proposal Would Require Independent Board Major...  Business"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhI5nxvYoYXS"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6kDEl6joZzz",
        "outputId": "12004010-2fce-4aa5-b36c-674e0d957efc"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "STOPWORDS = stopwords.words('english')\n",
        "print (STOPWORDS[:5])\n",
        "porter = PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['i', 'me', 'my', 'myself', 'we']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dBgIlLlobSz"
      },
      "source": [
        "def preprocess(text, stopwords=STOPWORDS):\n",
        "    \"\"\"Conditional preprocessing on our text unique to our task.\"\"\"\n",
        "    # Lower\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove stopwords\n",
        "    pattern = re.compile(r'\\b(' + r'|'.join(stopwords) + r')\\b\\s*')\n",
        "    text = pattern.sub('', text)\n",
        "\n",
        "    # Remove words in paranthesis\n",
        "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
        "\n",
        "    # Spacing and filters\n",
        "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\n",
        "    text = re.sub('[^A-Za-z0-9]+', ' ', text) # remove non alphanumeric chars\n",
        "    text = re.sub(' +', ' ', text)  # remove multiple spaces\n",
        "    text = text.strip()\n",
        "\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q61xQnTroc7q",
        "outputId": "b25d593d-70ed-4624-a0ae-96d3714b0c0a"
      },
      "source": [
        "# Sample\n",
        "text = \"Great week for the NYSE!\"\n",
        "preprocess(text=text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'great week nyse'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzaiMBheogHJ",
        "outputId": "779a612a-5059-49d6-db7b-dc3b0fd43468"
      },
      "source": [
        "# Apply to dataframe\n",
        "preprocessed_df = df.copy()\n",
        "preprocessed_df.title = preprocessed_df.title.apply(preprocess)\n",
        "print (f\"{df.title.values[0]}\\n\\n{preprocessed_df.title.values[0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GE lights up as its sales explode\n",
            "\n",
            "ge lights sales explode\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIuhzmkmoh4l"
      },
      "source": [
        "import collections\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFWj8_ZEomVM"
      },
      "source": [
        "TRAIN_SIZE = 0.7\n",
        "VAL_SIZE = 0.15\n",
        "TEST_SIZE = 0.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxPd6pwNonYM"
      },
      "source": [
        "def train_val_test_split(X, y, train_size):\n",
        "    \"\"\"Split dataset into data splits.\"\"\"\n",
        "    X_train, X_, y_train, y_ = train_test_split(X, y, train_size=TRAIN_SIZE, stratify=y)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size=0.5, stratify=y_)\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXFQK1wqoots"
      },
      "source": [
        "# Data\n",
        "X = preprocessed_df[\"title\"].values\n",
        "y = preprocessed_df[\"category\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faCU3-wBop9c",
        "outputId": "58fe9582-8093-400c-83a1-9a72cff862b9"
      },
      "source": [
        "# Create data splits\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\n",
        "    X=X, y=y, train_size=TRAIN_SIZE)\n",
        "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
        "print (f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "print (f\"Sample point: {X_train[0]} → {y_train[0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: (84000,), y_train: (84000,)\n",
            "X_val: (18000,), y_val: (18000,)\n",
            "X_test: (18000,), y_test: (18000,)\n",
            "Sample point: cassini flies past saturn moon titan today → Sci/Tech\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXhtScZJorK0"
      },
      "source": [
        "import itertools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCAS-Bkuospl"
      },
      "source": [
        "class LabelEncoder(object):\n",
        "    def __init__(self, class_to_index={}):\n",
        "        self.class_to_index = class_to_index\n",
        "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
        "        self.classes = list(self.class_to_index.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.class_to_index)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<LabelEncoder(num_classes={len(self)}>\"\n",
        "\n",
        "    def fit(self, y):\n",
        "        classes = np.unique(y)\n",
        "        for i, class_ in enumerate(classes):\n",
        "            self.class_to_index[class_] = i\n",
        "\n",
        "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
        "        self.classes = list(self.class_to_index.keys())\n",
        "        return self\n",
        "\n",
        "    def encode(self, y):\n",
        "        encoded = np.zeros(len(y), dtype=int)\n",
        "        for i, item in enumerate(y):\n",
        "            encoded[i] = self.class_to_index[item]\n",
        "        return encoded\n",
        "\n",
        "    def decode(self, y):\n",
        "        classes = []\n",
        "        for i, item in enumerate(y):\n",
        "            classes.append(self.index_to_class[item])\n",
        "\n",
        "    def save(self, fp):\n",
        "        with open(fp, 'w') as fp:\n",
        "            content = {\"class_to_index\": self.class_to_index}\n",
        "            json.dump(content, fp, indent=4, sort_keys=False)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, fp):\n",
        "        with open(fp, 'r') as fp:\n",
        "            kwargs = json.load(fp=fp)\n",
        "        return cls(**kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBxpkxa-qj2c",
        "outputId": "5fdeb8f8-e107-4397-b4ec-6b5a36fa2620"
      },
      "source": [
        "# Encode\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_train)\n",
        "NUM_CLASSES = len(label_encoder)\n",
        "label_encoder.class_to_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0, 1: 1, 2: 2, 3: 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a1qSeeHrDdc",
        "outputId": "34d685f5-4bbc-45d5-bc4d-a92a66459069"
      },
      "source": [
        "# Convert labels to tokens\n",
        "print (f\"y_train[0]: {y_train[0]}\")\n",
        "y_train = label_encoder.encode(y_train)\n",
        "y_val = label_encoder.encode(y_val)\n",
        "y_test = label_encoder.encode(y_test)\n",
        "print (f\"y_train[0]: {y_train[0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train[0]: Sci/Tech\n",
            "y_train[0]: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izRvKSQdrGaK",
        "outputId": "310f13a5-dedf-4754-ccc5-641e1c3fe1c9"
      },
      "source": [
        "# Class weights\n",
        "counts = np.bincount(y_train)\n",
        "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
        "print (f\"counts: {counts}\\nweights: {class_weights}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "counts: [21000 21000 21000 21000]\n",
            "weights: {0: 4.761904761904762e-05, 1: 4.761904761904762e-05, 2: 4.761904761904762e-05, 3: 4.761904761904762e-05}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_tGuShBrH7q"
      },
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "from more_itertools import take"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBMnBuO_rKWc"
      },
      "source": [
        "class Tokenizer(object):\n",
        "    def __init__(self, char_level, num_tokens=None,\n",
        "                 pad_token='<PAD>', oov_token='<UNK>',\n",
        "                 token_to_index=None):\n",
        "        self.char_level = char_level\n",
        "        self.separator = '' if self.char_level else ' '\n",
        "        if num_tokens: num_tokens -= 2 # pad + unk tokens\n",
        "        self.num_tokens = num_tokens\n",
        "        self.pad_token = pad_token\n",
        "        self.oov_token = oov_token\n",
        "        if not token_to_index:\n",
        "            token_to_index = {pad_token: 0, oov_token: 1}\n",
        "        self.token_to_index = token_to_index\n",
        "        self.index_to_token = {v: k for k, v in self.token_to_index.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_to_index)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Tokenizer(num_tokens={len(self)})>\"\n",
        "\n",
        "    def fit_on_texts(self, texts):\n",
        "        if not self.char_level:\n",
        "            texts = [text.split(\" \") for text in texts]\n",
        "        all_tokens = [token for text in texts for token in text]\n",
        "        counts = Counter(all_tokens).most_common(self.num_tokens)\n",
        "        self.min_token_freq = counts[-1][1]\n",
        "        for token, count in counts:\n",
        "            index = len(self)\n",
        "            self.token_to_index[token] = index\n",
        "            self.index_to_token[index] = token\n",
        "        return self\n",
        "\n",
        "    def texts_to_sequences(self, texts):\n",
        "        sequences = []\n",
        "        for text in texts:\n",
        "            if not self.char_level:\n",
        "                text = text.split(' ')\n",
        "            sequence = []\n",
        "            for token in text:\n",
        "                sequence.append(self.token_to_index.get(\n",
        "                    token, self.token_to_index[self.oov_token]))\n",
        "            sequences.append(np.asarray(sequence))\n",
        "        return sequences\n",
        "\n",
        "    def sequences_to_texts(self, sequences):\n",
        "        texts = []\n",
        "        for sequence in sequences:\n",
        "            text = []\n",
        "            for index in sequence:\n",
        "                text.append(self.index_to_token.get(index, self.oov_token))\n",
        "            texts.append(self.separator.join([token for token in text]))\n",
        "        return texts\n",
        "\n",
        "    def save(self, fp):\n",
        "        with open(fp, 'w') as fp:\n",
        "            contents = {\n",
        "                'char_level': self.char_level,\n",
        "                'oov_token': self.oov_token,\n",
        "                'token_to_index': self.token_to_index\n",
        "            }\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, fp):\n",
        "        with open(fp, 'r') as fp:\n",
        "            kwargs = json.load(fp=fp)\n",
        "        return cls(**kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mq63G44euIAH",
        "outputId": "87b7863d-9064-4dda-a2a8-ea83859a2c4b"
      },
      "source": [
        "# Tokenize\n",
        "tokenizer = Tokenizer(char_level=False, num_tokens=5000)\n",
        "tokenizer.fit_on_texts(texts=X_train)\n",
        "VOCAB_SIZE = len(tokenizer)\n",
        "print (tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Tokenizer(num_tokens=5000)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1G51Hexu8v2",
        "outputId": "ec2e20fd-e41b-43c9-eeeb-941d86bf1084"
      },
      "source": [
        "# Sample of tokens\n",
        "print (take(5, tokenizer.token_to_index.items()))\n",
        "print (f\"least freq token's freq: {tokenizer.min_token_freq}\") # use this to adjust num_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('<PAD>', 0), ('<UNK>', 1), ('39', 2), ('gt', 3), ('b', 4)]\n",
            "least freq token's freq: 14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSaquc-QxPnI",
        "outputId": "cfbaeb6c-30cf-4c69-a681-bc30e44af41e"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['cassini flies past saturn moon titan today',\n",
              "       'nintendo says touching good sexed ds ads',\n",
              "       'sigourney weaver books flight virgin galactica', ...,\n",
              "       'barrichello makes early running',\n",
              "       'still believe eta train bomb link says aznar',\n",
              "       'new orion workstation puts cluster box'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_l10b2bFvA_l",
        "outputId": "54711d1c-0a90-4f48-9b82-c023cfe4f01e"
      },
      "source": [
        "# Convert texts to sequences of indices\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "preprocessed_text = tokenizer.sequences_to_texts([X_train[0]])[0]\n",
        "print (\"Text to indices:\\n\"\n",
        "    f\"  (preprocessed) → {preprocessed_text}\\n\"\n",
        "    f\"  (tokenized) → {X_train[0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text to indices:\n",
            "  (preprocessed) → cassini flies past saturn moon titan today\n",
            "  (tokenized) → [1273 2354  282 1303  725 1091  650]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CojjwAB71TO",
        "outputId": "9e5876fe-f0c0-4b5a-9147-016fb0ef5e35"
      },
      "source": [
        "len(tokenizer.token_to_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOwxiVKBvHj3",
        "outputId": "2b4cfba0-8b38-4746-e0fd-7ccdd3e96e97"
      },
      "source": [
        "# Input\n",
        "vocab_size = 10\n",
        "x = torch.randint(high=vocab_size, size=(1,5))\n",
        "print (x)\n",
        "print (x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[8, 5, 5, 4, 4]])\n",
            "torch.Size([1, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pU247bz3x6sl",
        "outputId": "a2c191eb-9330-4f0d-e6af-a549452f95a7"
      },
      "source": [
        "# Embedding layer\n",
        "embeddings = nn.Embedding(embedding_dim=100, num_embeddings=vocab_size)\n",
        "print (embeddings.weight.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-tTeQiFyPe7",
        "outputId": "baebc52c-ef73-4829-d3df-6f7ce0e41112"
      },
      "source": [
        "# Embed the input\n",
        "embeddings(x).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU-grhWYyS1U"
      },
      "source": [
        "def pad_sequences(sequences, max_seq_len=0):\n",
        "    \"\"\"Pad sequences to max length in sequence.\"\"\"\n",
        "    max_seq_len = max(max_seq_len, max(len(sequence) for sequence in sequences))\n",
        "    padded_sequences = np.zeros((len(sequences), max_seq_len))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        padded_sequences[i][:len(sequence)] = sequence\n",
        "    return padded_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0iVswxWyjrb",
        "outputId": "05a384b5-2a5f-435c-99e7-8fd9cd7368cf"
      },
      "source": [
        "# 2D sequences\n",
        "padded = pad_sequences(X_train[0:3])\n",
        "print (padded.shape)\n",
        "print (padded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 7)\n",
            "[[1.273e+03 2.354e+03 2.820e+02 1.303e+03 7.250e+02 1.091e+03 6.500e+02]\n",
            " [8.950e+02 9.000e+00 1.000e+00 3.070e+02 1.000e+00 1.723e+03 1.081e+03]\n",
            " [1.000e+00 1.000e+00 2.063e+03 4.260e+02 1.001e+03 1.000e+00 0.000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oQk5ntJyoPq"
      },
      "source": [
        "FILTER_SIZES = list(range(1, 4)) # uni, bi and tri grams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cETwt2ziysVp"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, max_filter_size):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.max_filter_size = max_filter_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Dataset(N={len(self)})>\"\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X = self.X[index]\n",
        "        y = self.y[index]\n",
        "        return [X, y]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        \"\"\"Processing on a batch.\"\"\"\n",
        "        # Get inputs\n",
        "        batch = np.array(batch, dtype=object)\n",
        "        X = batch[:, 0]\n",
        "        y = np.stack(batch[:, 1], axis=0)\n",
        "\n",
        "        # Pad sequences\n",
        "        X = pad_sequences(X)\n",
        "\n",
        "        # Cast\n",
        "        X = torch.LongTensor(X.astype(np.int32))\n",
        "        y = torch.LongTensor(y.astype(np.int32))\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def create_dataloader(self, batch_size, shuffle=False, drop_last=False):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            dataset=self, batch_size=batch_size, collate_fn=self.collate_fn,\n",
        "            shuffle=shuffle, drop_last=drop_last, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN2wjtTSyz7K",
        "outputId": "1078988d-4117-47ba-ddc4-f33252dfe940"
      },
      "source": [
        "# Create datasets\n",
        "max_filter_size = max(FILTER_SIZES)\n",
        "train_dataset = Dataset(X=X_train, y=y_train, max_filter_size=max_filter_size)\n",
        "val_dataset = Dataset(X=X_val, y=y_val, max_filter_size=max_filter_size)\n",
        "test_dataset = Dataset(X=X_test, y=y_test, max_filter_size=max_filter_size)\n",
        "print (\"Datasets:\\n\"\n",
        "    f\"  Train dataset:{train_dataset.__str__()}\\n\"\n",
        "    f\"  Val dataset: {val_dataset.__str__()}\\n\"\n",
        "    f\"  Test dataset: {test_dataset.__str__()}\\n\"\n",
        "    \"Sample point:\\n\"\n",
        "    f\"  X: {train_dataset[0][0]}\\n\"\n",
        "    f\"  y: {train_dataset[0][1]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datasets:\n",
            "  Train dataset:<Dataset(N=84000)>\n",
            "  Val dataset: <Dataset(N=18000)>\n",
            "  Test dataset: <Dataset(N=18000)>\n",
            "Sample point:\n",
            "  X: [1273 2354  282 1303  725 1091  650]\n",
            "  y: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxfpZSAiy4_j",
        "outputId": "89d5d808-2e67-429d-831d-aa95ed6e102a"
      },
      "source": [
        "# Create dataloaders\n",
        "batch_size = 64\n",
        "train_dataloader = train_dataset.create_dataloader(batch_size=batch_size)\n",
        "val_dataloader = val_dataset.create_dataloader(batch_size=batch_size)\n",
        "test_dataloader = test_dataset.create_dataloader(batch_size=batch_size)\n",
        "batch_X, batch_y = next(iter(train_dataloader))\n",
        "print (\"Sample batch:\\n\"\n",
        "    f\"  X: {list(batch_X.size())}\\n\"\n",
        "    f\"  y: {list(batch_y.size())}\\n\"\n",
        "    \"Sample point:\\n\"\n",
        "    f\"  X: {batch_X[0]}\\n\"\n",
        "    f\"  y: {batch_y[0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample batch:\n",
            "  X: [64, 9]\n",
            "  y: [64]\n",
            "Sample point:\n",
            "  X: tensor([1273, 2354,  282, 1303,  725, 1091,  650,    0,    0])\n",
            "  y: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPdPJ0wty7Q9"
      },
      "source": [
        "1. We'll first tokenize our inputs `(batch_size, max_seq_len)`.\n",
        "2. Then we'll embed our tokenized inputs `(batch_size, max_seq_len, embedding_dim)`.\n",
        "3. We'll apply convolution via filters `(filter_size, vocab_size, num_filters)` followed by batch normalization. Our filters act as character level n-gram detecors. We have three different filter sizes `(2, 3 and 4)` and they will act as bi-gram, tri-gram and 4-gram feature extractors, respectivelyy.\n",
        "4. We'll apply 1D global max pooling which will extract the most relevant information from the feature maps for making the decision.\n",
        "5. We feed the pool outputs to a fully-connected (FC) layer (with dropout).\n",
        "6. We use one more FC layer with softmax to derive class probabilities\n",
        "\n",
        "[Model](https://raw.githubusercontent.com/GokuMohandas/MadeWithML/main/images/basics/embeddings/model.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9KUEDK2zc8C"
      },
      "source": [
        "import math\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58oxWiDEzyTy"
      },
      "source": [
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 100\n",
        "DROPOUT_P = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcBnmleWzzz6"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, vocab_size, num_filters,\n",
        "                 filter_sizes, hidden_dim, dropout_p, num_classes,\n",
        "                 pretrained_embeddings=None, freeze_embeddings=False,\n",
        "                 padding_idx=0):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Filter sizes\n",
        "        self.filter_sizes = filter_sizes\n",
        "\n",
        "        # Initialize embeddings\n",
        "        if pretrained_embeddings is None:\n",
        "            self.embeddings = nn.Embedding(\n",
        "                embedding_dim=embedding_dim, num_embeddings=vocab_size,\n",
        "                padding_idx=padding_idx)\n",
        "        else:\n",
        "            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\n",
        "            self.embeddings = nn.Embedding(\n",
        "                embedding_dim=embedding_dim, num_embeddings=vocab_size,\n",
        "                padding_idx=padding_idx, _weight=pretrained_embeddings)\n",
        "\n",
        "        # Freeze embeddings or not\n",
        "        if freeze_embeddings:\n",
        "            self.embeddings.weight.requires_grad = False\n",
        "\n",
        "        # Conv weights\n",
        "        self.conv = nn.ModuleList(\n",
        "            [nn.Conv1d(in_channels=embedding_dim,\n",
        "                       out_channels=num_filters,\n",
        "                       kernel_size=f) for f in filter_sizes])\n",
        "\n",
        "        # FC weights\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc1 = nn.Linear(num_filters*len(filter_sizes), hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, inputs, channel_first=False, apply_softmax=False):\n",
        "\n",
        "        # Embed\n",
        "        x_in, = inputs\n",
        "        x_in = self.embeddings(x_in)\n",
        "\n",
        "        # Rearrange input so num_channels is in dim 1 (N, C, L)\n",
        "        if not channel_first:\n",
        "            x_in = x_in.transpose(1, 2)\n",
        "\n",
        "        # Conv outputs\n",
        "        z = []\n",
        "        max_seq_len = x_in.shape[2]\n",
        "        for i, f in enumerate(self.filter_sizes):\n",
        "            # `SAME` padding\n",
        "            padding_left = int((self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2)\n",
        "            padding_right = int(math.ceil((self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2))\n",
        "\n",
        "            # Conv + pool\n",
        "            _z = self.conv[i](F.pad(x_in, (padding_left, padding_right)))\n",
        "            _z = F.max_pool1d(_z, _z.size(2)).squeeze(2)\n",
        "            z.append(_z)\n",
        "\n",
        "        # Concat conv outputs\n",
        "        z = torch.cat(z, 1)\n",
        "\n",
        "        # FC layers\n",
        "        z = self.fc1(z)\n",
        "        z = self.dropout(z)\n",
        "        y_pred = self.fc2(z)\n",
        "\n",
        "        if apply_softmax:\n",
        "            y_pred = F.softmax(y_pred, dim=1)\n",
        "        return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul4eeJbH3iIU"
      },
      "source": [
        "def load_glove_embeddings(embeddings_file):\n",
        "    \"\"\"Load embeddings from a file.\"\"\"\n",
        "    embeddings = {}\n",
        "    with open(embeddings_file, \"r\") as fp:\n",
        "        for index, line in enumerate(fp):\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            embedding = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings[word] = embedding\n",
        "    return embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfqnuBG_5xex"
      },
      "source": [
        "def make_embeddings_matrix(embeddings, word_index, embedding_dim):\n",
        "    \"\"\"Create embeddings matrix to use in Embedding layer.\"\"\"\n",
        "    embedding_matrix = np.zeros((len(word_index), embedding_dim))\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = embeddings.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnPmVN-A5yXp",
        "outputId": "cbf933f1-61da-4444-8872-d314a9dd7e33"
      },
      "source": [
        "# Create embeddings\n",
        "embeddings_file = 'glove.6B.{0}d.txt'.format(EMBEDDING_DIM)\n",
        "glove_embeddings = load_glove_embeddings(embeddings_file=embeddings_file)\n",
        "embedding_matrix = make_embeddings_matrix(\n",
        "    embeddings=glove_embeddings, word_index=tokenizer.token_to_index,\n",
        "    embedding_dim=EMBEDDING_DIM)\n",
        "print (f\"<Embeddings(words={embedding_matrix.shape[0]}, dim={embedding_matrix.shape[1]})>\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Embeddings(words=5000, dim=100)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUgBWpsa68qA",
        "outputId": "38f7755e-4e97-4ee2-8dec-30ed620e5c2c"
      },
      "source": [
        "len(tokenizer.token_to_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9RbFh-m7ckQ"
      },
      "source": [
        "import json\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from torch.optim import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zzf6TaZr8OTf"
      },
      "source": [
        "NUM_FILTERS = 50\n",
        "LEARNING_RATE = 1e-3\n",
        "PATIENCE = 5\n",
        "NUM_EPOCHS = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FZf__G_8bSW"
      },
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, model, device, loss_fn=None, optimizer=None, scheduler=None):\n",
        "\n",
        "        # Set params\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "    def train_step(self, dataloader):\n",
        "        \"\"\"Train step.\"\"\"\n",
        "        # Set model to train mode\n",
        "        self.model.train()\n",
        "        loss = 0.0\n",
        "\n",
        "        # Iterate over train batches\n",
        "        for i, batch in enumerate(dataloader):\n",
        "\n",
        "            # Step\n",
        "            batch = [item.to(self.device) for item in batch]  # Set device\n",
        "            inputs, targets = batch[:-1], batch[-1]\n",
        "            self.optimizer.zero_grad()  # Reset gradients\n",
        "            z = self.model(inputs)  # Forward pass\n",
        "            J = self.loss_fn(z, targets)  # Define loss\n",
        "            J.backward()  # Backward pass\n",
        "            self.optimizer.step()  # Update weights\n",
        "\n",
        "            # Cumulative Metrics\n",
        "            loss += (J.detach().item() - loss) / (i + 1)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def eval_step(self, dataloader):\n",
        "        \"\"\"Validation or test step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        loss = 0.0\n",
        "        y_trues, y_probs = [], []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Step\n",
        "                batch = [item.to(self.device) for item in batch]  # Set device\n",
        "                inputs, y_true = batch[:-1], batch[-1]\n",
        "                z = self.model(inputs)  # Forward pass\n",
        "                J = self.loss_fn(z, y_true).item()\n",
        "\n",
        "                # Cumulative Metrics\n",
        "                loss += (J - loss) / (i + 1)\n",
        "\n",
        "                # Store outputs\n",
        "                y_prob = torch.sigmoid(z).cpu().numpy()\n",
        "                y_probs.extend(y_prob)\n",
        "                y_trues.extend(y_true.cpu().numpy())\n",
        "\n",
        "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
        "\n",
        "    def predict_step(self, dataloader):\n",
        "        \"\"\"Prediction step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        y_probs = []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Forward pass w/ inputs\n",
        "                inputs, targets = batch[:-1], batch[-1]\n",
        "                y_prob = self.model(inputs, apply_softmax=True)\n",
        "\n",
        "                # Store outputs\n",
        "                y_probs.extend(y_prob)\n",
        "\n",
        "        return np.vstack(y_probs)\n",
        "\n",
        "    def train(self, num_epochs, patience, train_dataloader, val_dataloader):\n",
        "        best_val_loss = np.inf\n",
        "        train_loss = np.inf\n",
        "        val_loss = np.inf\n",
        "        for epoch in range(num_epochs):\n",
        "            # Steps\n",
        "            train_loss = self.train_step(dataloader=train_dataloader)\n",
        "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
        "            self.scheduler.step(val_loss)\n",
        "\n",
        "            # Early stopping\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = self.model\n",
        "                _patience = patience  # reset _patience\n",
        "            else:\n",
        "                _patience -= 1\n",
        "            if not _patience:  # 0\n",
        "                print(\"Stopping early!\")\n",
        "                break\n",
        "\n",
        "            # Logging\n",
        "            print(\n",
        "                f\"Epoch: {epoch+1} | \"\n",
        "                f\"train_loss: {train_loss:.5f}, \"\n",
        "                f\"val_loss: {val_loss:.5f}, \"\n",
        "                f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
        "                f\"_patience: {_patience}\"\n",
        "            )\n",
        "        return best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xr7je9X_51L"
      },
      "source": [
        "def get_metrics(y_true, y_pred, classes):\n",
        "    \"\"\"Per-class performance metrics.\"\"\"\n",
        "    # Performance\n",
        "    performance = {\"overall\": {}, \"class\": {}}\n",
        "\n",
        "    # Overall performance\n",
        "    metrics = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "    performance[\"overall\"][\"precision\"] = metrics[0]\n",
        "    performance[\"overall\"][\"recall\"] = metrics[1]\n",
        "    performance[\"overall\"][\"f1\"] = metrics[2]\n",
        "    performance[\"overall\"][\"num_samples\"] = np.float64(len(y_true))\n",
        "\n",
        "    # Per-class performance\n",
        "    metrics = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
        "    for i in range(len(classes)):\n",
        "        performance[\"class\"][classes[i]] = {\n",
        "            \"precision\": metrics[0][i],\n",
        "            \"recall\": metrics[1][i],\n",
        "            \"f1\": metrics[2][i],\n",
        "            \"num_samples\": np.float64(metrics[3][i]),\n",
        "        }\n",
        "\n",
        "    return performance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arxv-3c7_7A7"
      },
      "source": [
        "PRETRAINED_EMBEDDINGS = None\n",
        "FREEZE_EMBEDDINGS = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFdrhXPN_8bj",
        "outputId": "77ccd24d-e177-40e0-a360-2cd3fbce3f31"
      },
      "source": [
        "# Initialize model\n",
        "model = CNN(\n",
        "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\n",
        "    num_filters=NUM_FILTERS, filter_sizes=FILTER_SIZES,\n",
        "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES,\n",
        "    pretrained_embeddings=PRETRAINED_EMBEDDINGS, freeze_embeddings=FREEZE_EMBEDDINGS)\n",
        "model = model.to(device) # set device\n",
        "print (model.named_parameters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.named_parameters of CNN(\n",
            "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
            "  (conv): ModuleList(\n",
            "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
            "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
            "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QNGGZGq_9as"
      },
      "source": [
        "# Define Loss\n",
        "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9v3iEiT_--B"
      },
      "source": [
        "# Define optimizer & scheduler\n",
        "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.1, patience=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0qxV0zjALDj"
      },
      "source": [
        "# Trainer module\n",
        "trainer = Trainer(\n",
        "    model=model, device=device, loss_fn=loss_fn,\n",
        "    optimizer=optimizer, scheduler=scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvZ7BOecAMd8",
        "outputId": "c453a12c-9b48-46e3-8279-e7711bb427d3"
      },
      "source": [
        "# Train\n",
        "best_model = trainer.train(\n",
        "    2, PATIENCE, train_dataloader, val_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.76523, val_loss: 0.59388, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 2 | train_loss: 0.49377, val_loss: 0.55256, lr: 1.00E-03, _patience: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MESLnGYLANaL"
      },
      "source": [
        "# Get predictions\n",
        "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
        "y_pred = np.argmax(y_prob, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZKYrLDuC4I4",
        "outputId": "a223dd16-2f49-48bd-a739-b2d0b9c04616"
      },
      "source": [
        "# Determine performance\n",
        "performance = get_metrics(\n",
        "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
        "print (json.dumps(performance['overall'], indent=2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"precision\": 0.8045775146937677,\n",
            "  \"recall\": 0.8019444444444445,\n",
            "  \"f1\": 0.8008436562412699,\n",
            "  \"num_samples\": 18000.0\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE8bWf20C5mh"
      },
      "source": [
        "PRETRAINED_EMBEDDINGS = embedding_matrix\n",
        "FREEZE_EMBEDDINGS = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3AXi40mC7Qo",
        "outputId": "b8936157-928c-42d4-b599-b92a999485ef"
      },
      "source": [
        "# Initialize model\n",
        "model = CNN(\n",
        "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\n",
        "    num_filters=NUM_FILTERS, filter_sizes=FILTER_SIZES,\n",
        "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES,\n",
        "    pretrained_embeddings=PRETRAINED_EMBEDDINGS, freeze_embeddings=FREEZE_EMBEDDINGS)\n",
        "model = model.to(device) # set device\n",
        "print (model.named_parameters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.named_parameters of CNN(\n",
            "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
            "  (conv): ModuleList(\n",
            "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
            "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
            "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gNdB17XC97Y"
      },
      "source": [
        "# Define Loss\n",
        "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
        "loss = nn.CrossEntropyLoss(weight=class_weights_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KiavDggC_dJ"
      },
      "source": [
        "# Define optimizer & scheduler\n",
        "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.1, patience=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46Yqh8dsDAoY"
      },
      "source": [
        "# Trainer module\n",
        "trainer = Trainer(\n",
        "    model=model, device=device, loss_fn=loss_fn,\n",
        "    optimizer=optimizer, scheduler=scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrBl_tSYDBvQ",
        "outputId": "683918e7-cf4e-42c8-bc50-f53b7715ac6c"
      },
      "source": [
        "# Train\n",
        "best_model = trainer.train(\n",
        "    2, PATIENCE, train_dataloader, val_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.51737, val_loss: 0.49053, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 2 | train_loss: 0.44296, val_loss: 0.48141, lr: 1.00E-03, _patience: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65yekI84DE14"
      },
      "source": [
        "# Get predictions\n",
        "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
        "y_pred = np.argmax(y_prob, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke6UdYxFDIt_",
        "outputId": "88c77bc1-f2c7-45bf-c002-1ac3c9429966"
      },
      "source": [
        "# Determine performance\n",
        "performance = get_metrics(\n",
        "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
        "print (json.dumps(performance['overall'], indent=2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"precision\": 0.8322591497364493,\n",
            "  \"recall\": 0.8268888888888889,\n",
            "  \"f1\": 0.8268362002648042,\n",
            "  \"num_samples\": 18000.0\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YvNgbkMDOP4"
      },
      "source": [
        "PRETRAINED_EMBEDDINGS = embedding_matrix\n",
        "FREEZE_EMBEDDINGS = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw18pw1FDSWw",
        "outputId": "af32cd3d-d5e6-417b-c8da-493fe90b58b5"
      },
      "source": [
        "# Initialize model\n",
        "model = CNN(\n",
        "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\n",
        "    num_filters=NUM_FILTERS, filter_sizes=FILTER_SIZES,\n",
        "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES,\n",
        "    pretrained_embeddings=PRETRAINED_EMBEDDINGS, freeze_embeddings=FREEZE_EMBEDDINGS)\n",
        "model = model.to(device) # set device\n",
        "print (model.named_parameters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.named_parameters of CNN(\n",
            "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
            "  (conv): ModuleList(\n",
            "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
            "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
            "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2zdwYTTDT5R"
      },
      "source": [
        "# Define Loss\n",
        "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
        "loss = nn.CrossEntropyLoss(weight=class_weights_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLZJvRTkDVew"
      },
      "source": [
        "# Define optimizer & scheduler\n",
        "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.1, patience=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idPi3EeGDX9I"
      },
      "source": [
        "# Trainer module\n",
        "trainer = Trainer(\n",
        "    model=model, device=device, loss_fn=loss_fn,\n",
        "    optimizer=optimizer, scheduler=scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29cZgMGLDZSn",
        "outputId": "6ff98a64-d063-4506-fcc8-1899fed4aebc"
      },
      "source": [
        "# Train\n",
        "best_model = trainer.train(\n",
        "    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.48926, val_loss: 0.45016, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 2 | train_loss: 0.39166, val_loss: 0.44004, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 3 | train_loss: 0.34678, val_loss: 0.45493, lr: 1.00E-03, _patience: 4\n",
            "Epoch: 4 | train_loss: 0.30493, val_loss: 0.49032, lr: 1.00E-03, _patience: 3\n",
            "Epoch: 5 | train_loss: 0.26296, val_loss: 0.54490, lr: 1.00E-03, _patience: 2\n",
            "Epoch: 6 | train_loss: 0.22051, val_loss: 0.62523, lr: 1.00E-04, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N0i0pHPDat3"
      },
      "source": [
        "# Get predictions\n",
        "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
        "y_pred = np.argmax(y_prob, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1Wl54T2DeZg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "314d8cdd-ac1e-4542-fb23-b169ea8b584e"
      },
      "source": [
        "# Determine performance\n",
        "performance = get_metrics(\n",
        "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
        "print (json.dumps(performance['overall'], indent=2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"precision\": 0.8323596772722246,\n",
            "  \"recall\": 0.8328333333333333,\n",
            "  \"f1\": 0.8323764984021081,\n",
            "  \"num_samples\": 18000.0\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT-dA4MEDhuo"
      },
      "source": [
        "# Save artifacts\n",
        "from pathlib import Path\n",
        "dir = Path(\"cnn\")\n",
        "dir.mkdir(parents=True, exist_ok=True)\n",
        "label_encoder.save(fp=Path(dir, 'label_encoder.json'))\n",
        "tokenizer.save(fp=Path(dir, 'tokenizer.json'))\n",
        "torch.save(best_model.state_dict(), Path(dir, 'model.pt'))\n",
        "with open(Path(dir, 'performance.json'), \"w\") as fp:\n",
        "    json.dump(performance, indent=2, sort_keys=False, fp=fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVFwRwKiEJ53"
      },
      "source": [
        "def get_probability_distribution(y_prob, classes):\n",
        "    \"\"\"Create a dict of class probabilities from an array.\"\"\"\n",
        "    results = {}\n",
        "    for i, class_ in enumerate(classes):\n",
        "        results[class_] = np.float64(y_prob[i])\n",
        "    sorted_results = {k: v for k, v in sorted(\n",
        "        results.items(), key=lambda item: item[1], reverse=True)}\n",
        "    return sorted_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ercbyi7ERZX",
        "outputId": "caf90bf8-30b3-4411-de10-fe24cd732145"
      },
      "source": [
        "# Load artifacts\n",
        "device = torch.device(\"cpu\")\n",
        "label_encoder = LabelEncoder.load(fp=Path(dir, 'label_encoder.json'))\n",
        "tokenizer = Tokenizer.load(fp=Path(dir, 'tokenizer.json'))\n",
        "model = CNN(\n",
        "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\n",
        "    num_filters=NUM_FILTERS, filter_sizes=FILTER_SIZES,\n",
        "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES,\n",
        "    pretrained_embeddings=PRETRAINED_EMBEDDINGS, freeze_embeddings=FREEZE_EMBEDDINGS)\n",
        "model.load_state_dict(torch.load(Path(dir, 'model.pt'), map_location=device))\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
              "  (conv): ModuleList(\n",
              "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
              "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
              "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
              "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei-a6uXaES7H"
      },
      "source": [
        "# Initialize trainer\n",
        "trainer = Trainer(model=model, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw7LDyZzEUeP",
        "outputId": "ec74ac2c-f387-47c8-b78d-4f9804f83970"
      },
      "source": [
        "# Dataloader\n",
        "text = \"The final tennis tournament starts next week.\"\n",
        "X = tokenizer.texts_to_sequences([preprocess(text)])\n",
        "print (tokenizer.sequences_to_texts(X))\n",
        "y_filler = label_encoder.encode([label_encoder.classes[0]]*len(X))\n",
        "dataset = Dataset(X=X, y=y_filler, max_filter_size=max_filter_size)\n",
        "dataloader = dataset.create_dataloader(batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['final tennis tournament starts next week']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "oM_fyxrmEVdf",
        "outputId": "5b102b3b-ca15-47c6-feeb-71c4fbe251d9"
      },
      "source": [
        "# Inference\n",
        "y_prob = trainer.predict_step(dataloader)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "label_encoder.decode(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-232-bdee828312db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-128-878f13b83b7d>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_to_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'LabelEncoder' object has no attribute 'index_to_class'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vy72nvysEW-f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}