{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLE82Bvo-CqO"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIirmZEX-UJc"
      },
      "source": [
        "SEED = 1234"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJerqGhU-VxA"
      },
      "source": [
        "def set_seeds(seed=1234):\n",
        "    \"\"\"set seeds for reproducibility\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) # for multi-gpu setup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsgdTuZf-pkC"
      },
      "source": [
        "set_seeds(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33gq__ky-sUx",
        "outputId": "41db01aa-3ba2-460f-8ff8-29ce2f0d9199"
      },
      "source": [
        "# cuda = False\n",
        "device = torch.device('cuda' if\n",
        "                      torch.cuda.is_available() else 'cpu')\n",
        "torch.set_default_tensor_type('torch.FloatTensor')\n",
        "if device.type == 'cuda':\n",
        "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "iqtIrmS__Ijw",
        "outputId": "43314e90-6142-49ab-bc7b-d5337f6a9cf0"
      },
      "source": [
        "# Load data\n",
        "url = \"https://raw.githubusercontent.com/GokuMohandas/MadeWithML/main/datasets/news.csv\"\n",
        "df = pd.read_csv(url, header=0) # load\n",
        "df = df.sample(frac=1).reset_index(drop=True) # shuffle\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sharon Accepts Plan to Reduce Gaza Army Operat...</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Internet Key Battleground in Wildlife Crime Fight</td>\n",
              "      <td>Sci/Tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>July Durable Good Orders Rise 1.7 Percent</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Growing Signs of a Slowing on Wall Street</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The New Faces of Reality TV</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  category\n",
              "0  Sharon Accepts Plan to Reduce Gaza Army Operat...     World\n",
              "1  Internet Key Battleground in Wildlife Crime Fight  Sci/Tech\n",
              "2          July Durable Good Orders Rise 1.7 Percent  Business\n",
              "3          Growing Signs of a Slowing on Wall Street  Business\n",
              "4                        The New Faces of Reality TV     World"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_el6kxx_LAx",
        "outputId": "3ca7e3b4-b2f5-4ee7-eef2-f59746372680"
      },
      "source": [
        "# unique news categories\n",
        "np.unique(df['category'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Business', 'Sci/Tech', 'Sports', 'World'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPWSX7na_USG"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSLouMyn_ic4",
        "outputId": "117dd110-1502-46ba-c7d8-f63eef6c927f"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "STOPWORDS = stopwords.words('english')\n",
        "print(f\"Stowords: {STOPWORDS[:5]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Stowords: ['i', 'me', 'my', 'myself', 'we']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn1h5-iM_1_8"
      },
      "source": [
        "porter = PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY0haKTM_6OO"
      },
      "source": [
        "def preprocess(text, stopwords=STOPWORDS):\n",
        "    \"\"\"conditional preprocessing on text\"\"\"\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # remove stopwords\n",
        "    pattern = re.compile(r'\\b(' + r'|'.join(stopwords) + r')\\b\\s*')\n",
        "    text = pattern.sub('', text)\n",
        "\n",
        "    # remove words in paranthesis\n",
        "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
        "\n",
        "    # Spacing and filters\n",
        "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\n",
        "    text = re.sub('[^A-Za-z0-9]+', ' ', text) # remove non alphanumeric chars\n",
        "    text = re.sub(' +', ' ', text)  # remove multiple spaces\n",
        "    text = text.strip()\n",
        "\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ipOVEYuuA6eX",
        "outputId": "7081390b-52e9-4248-a971-0190d550b667"
      },
      "source": [
        "# Sample\n",
        "text = \"Great week for the NYSE!\"\n",
        "preprocess(text=text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'great week nyse'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r_JGHADA797",
        "outputId": "b1c38377-8a4e-452d-d89a-e161c85401bc"
      },
      "source": [
        "# Apply to dataframe\n",
        "preprocessed_df = df.copy()\n",
        "preprocessed_df.title = preprocessed_df.title.apply(preprocess)\n",
        "print (f\"{df.title.values[0]}\\n\\n{preprocessed_df.title.values[0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sharon Accepts Plan to Reduce Gaza Army Operation, Haaretz Says\n",
            "\n",
            "sharon accepts plan reduce gaza army operation haaretz says\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi6NcU1nCBdW",
        "outputId": "fcc61244-77d9-404d-fdc2-68feb0cb8b09"
      },
      "source": [
        "preprocessed_df.title.values[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['sharon accepts plan reduce gaza army operation haaretz says',\n",
              "       'internet key battleground wildlife crime fight',\n",
              "       'july durable good orders rise 1 7 percent',\n",
              "       'growing signs slowing wall street', 'new faces reality tv'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7l8hzdSDEp7"
      },
      "source": [
        "import collections\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDn7SSO7DtXx"
      },
      "source": [
        "TRAIN_SIZE = 0.7\n",
        "VAL_SIZE = 0.15\n",
        "TEST_SIZE = 0.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkXjR6VbDyyx"
      },
      "source": [
        "def train_val_test_split(X, y, train_size):\n",
        "    \"\"\"Split dataset into data splits.\"\"\"\n",
        "    X_train, X_, y_train, y_ = train_test_split(X, y, train_size=TRAIN_SIZE, stratify=y)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size=0.5, stratify=y_)\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsJmO4K_D04x"
      },
      "source": [
        "# Data\n",
        "X = preprocessed_df[\"title\"].values\n",
        "y = preprocessed_df[\"category\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVC8AaXQD2G5",
        "outputId": "6e3a7f9c-ac27-494d-aba7-89926eeeaa93"
      },
      "source": [
        "# Create data splits\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\n",
        "    X=X, y=y, train_size=TRAIN_SIZE)\n",
        "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
        "print (f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "print (f\"Sample point: {X_train[0]} → {y_train[0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: (84000,), y_train: (84000,)\n",
            "X_val: (18000,), y_val: (18000,)\n",
            "X_test: (18000,), y_test: (18000,)\n",
            "Sample point: extinct humans left louse legacy → Sci/Tech\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftD8jQrxD3zR"
      },
      "source": [
        "import itertools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W87xuhhBEBgR"
      },
      "source": [
        "class LabelEncoder(object):\n",
        "    \"\"\"Label encoder for tag labels.\"\"\"\n",
        "    def __init__(self, class_to_index={}):\n",
        "        self.class_to_index = class_to_index\n",
        "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
        "        self.classes = list(self.class_to_index.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.class_to_index)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<LabelEncoder(num_classes={len(self)})>\"\n",
        "\n",
        "    def fit(self, y):\n",
        "        classes = np.unique(y)\n",
        "        for i, class_ in enumerate(classes):\n",
        "            self.class_to_index[class_] = i\n",
        "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
        "        self.classes = list(self.class_to_index.keys())\n",
        "        return self\n",
        "\n",
        "    def encode(self, y):\n",
        "        encoded = np.zeros((len(y)), dtype=int)\n",
        "        for i, item in enumerate(y):\n",
        "            encoded[i] = self.class_to_index[item]\n",
        "        return encoded\n",
        "\n",
        "    def decode(self, y):\n",
        "        classes = []\n",
        "        for i, item in enumerate(y):\n",
        "            classes.append(self.index_to_class[item])\n",
        "        return classes\n",
        "\n",
        "    def save(self, fp):\n",
        "        with open(fp, 'w') as fp:\n",
        "            contents = {'class_to_index': self.class_to_index}\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, fp):\n",
        "        with open(fp, 'r') as fp:\n",
        "            kwargs = json.load(fp=fp)\n",
        "        return cls(**kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQPyImMvGD5X",
        "outputId": "eb004594-76ae-4614-aca4-7c3dbf9aa6e5"
      },
      "source": [
        "# Encode\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_train)\n",
        "NUM_CLASSES = len(label_encoder)\n",
        "label_encoder.class_to_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Business': 0, 'Sci/Tech': 1, 'Sports': 2, 'World': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sydKpmv1GG0P",
        "outputId": "48605845-b6b6-446f-839b-816d65134fa7"
      },
      "source": [
        "# Convert labels to tokens\n",
        "print (f\"y_train[0]: {y_train[0]}\")\n",
        "y_train = label_encoder.encode(y_train)\n",
        "y_val = label_encoder.encode(y_val)\n",
        "y_test = label_encoder.encode(y_test)\n",
        "print (f\"y_train[0]: {y_train[0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train[0]: Sci/Tech\n",
            "y_train[0]: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pKLbJjXGKIA",
        "outputId": "90ad57af-6831-4bfe-a42f-a82e6464f689"
      },
      "source": [
        "# Class weights\n",
        "counts = np.bincount(y_train)\n",
        "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
        "print (f\"counts: {counts}\\nweights: {class_weights}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "counts: [21000 21000 21000 21000]\n",
            "weights: {0: 4.761904761904762e-05, 1: 4.761904761904762e-05, 2: 4.761904761904762e-05, 3: 4.761904761904762e-05}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5RTVC4xGMg2"
      },
      "source": [
        "# Tokenization\n",
        "import json\n",
        "from collections import Counter\n",
        "from more_itertools import take"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riV4azSYGbM2"
      },
      "source": [
        "class Tokenizer(object):\n",
        "    def __init__(self, char_level, num_tokens=None,\n",
        "                 pad_token='<PAD>', oov_token='<UNK>',\n",
        "                 token_to_index=None):\n",
        "        self.char_level = char_level\n",
        "        self.separator = '' if self.char_level else ' '\n",
        "        if num_tokens: num_tokens -= 2 # pad + unk tokens\n",
        "        self.num_tokens = num_tokens\n",
        "        self.pad_token = pad_token\n",
        "        self.oov_token = oov_token\n",
        "        if not token_to_index:\n",
        "            token_to_index = {pad_token: 0, oov_token: 1}\n",
        "        self.token_to_index = token_to_index\n",
        "        self.index_to_token = {v: k for k, v in self.token_to_index.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_to_index)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Tokenizer(num_tokens={len(self)})>\"\n",
        "\n",
        "    def fit_on_texts(self, texts):\n",
        "        if not self.char_level:\n",
        "            texts = [text.split(\" \") for text in texts]\n",
        "        all_tokens = [token for text in texts for token in text]\n",
        "        counts = Counter(all_tokens).most_common(self.num_tokens)\n",
        "        self.min_token_freq = counts[-1][1]\n",
        "        for token, count in counts:\n",
        "            index = len(self)\n",
        "            self.token_to_index[token] = index\n",
        "            self.index_to_token[index] = token\n",
        "        return self\n",
        "\n",
        "    def texts_to_sequences(self, texts):\n",
        "        print(type(texts))\n",
        "        sequences = []\n",
        "        for text in texts:\n",
        "            if not self.char_level:\n",
        "                text = text.split(' ')\n",
        "            sequence = []\n",
        "            for token in text:\n",
        "                sequence.append(self.token_to_index.get(\n",
        "                    token, self.token_to_index[self.oov_token]))\n",
        "            sequences.append(np.asarray(sequence))\n",
        "        return sequences\n",
        "\n",
        "    def sequences_to_texts(self, sequences):\n",
        "        texts = []\n",
        "        for sequence in sequences:\n",
        "            text = []\n",
        "            for index in sequence:\n",
        "                text.append(self.index_to_token.get(index, self.oov_token))\n",
        "            texts.append(self.separator.join([token for token in text]))\n",
        "        return texts\n",
        "\n",
        "    def save(self, fp):\n",
        "        with open(fp, 'w') as fp:\n",
        "            contents = {\n",
        "                'char_level': self.char_level,\n",
        "                'oov_token': self.oov_token,\n",
        "                'token_to_index': self.token_to_index\n",
        "            }\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, fp):\n",
        "        with open(fp, 'r') as fp:\n",
        "            kwargs = json.load(fp=fp)\n",
        "        return cls(**kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzE6uAmkwXuG",
        "outputId": "a54dfd15-cc3e-40fd-e24e-9ef11807a594"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['extinct humans left louse legacy',\n",
              "       'michigan st beats central conn st',\n",
              "       'least one saudi policeman killed clashes gunmen', ..., 'alan key',\n",
              "       'google founders honored marconi foundation',\n",
              "       'man builds 7 foot grandfather clock lego'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2zDqrd3CzRP",
        "outputId": "a1d167b5-0c57-4632-84c9-3c0fbb5dcc8f"
      },
      "source": [
        "# tokenize\n",
        "tokenizer = Tokenizer(char_level=False, num_tokens=500)\n",
        "tokenizer.fit_on_texts(texts=X_train)\n",
        "VOCAB_SIZE = len(tokenizer)\n",
        "print(tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Tokenizer(num_tokens=500)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnJXEIZnDI7S",
        "outputId": "170e3f2d-4635-416a-e3c8-fe91d4712f75"
      },
      "source": [
        "# Sample of tokens\n",
        "print (take(5, tokenizer.token_to_index.items()))\n",
        "print (f\"least freq token's freq: {tokenizer.min_token_freq}\") # use this to adjust num_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('<PAD>', 0), ('<UNK>', 1), ('39', 2), ('b', 3), ('gt', 4)]\n",
            "least freq token's freq: 165\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqDn4e8NDeVJ",
        "outputId": "cca952e3-4652-4d66-d789-dab138abe001"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['extinct humans left louse legacy',\n",
              "       'michigan st beats central conn st',\n",
              "       'least one saudi policeman killed clashes gunmen', ..., 'alan key',\n",
              "       'google founders honored marconi foundation',\n",
              "       'man builds 7 foot grandfather clock lego'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnY60fj_DQOY",
        "outputId": "0ebcae82-522b-486c-ada6-e785e21b914b"
      },
      "source": [
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "preprocessed_text = tokenizer.sequences_to_texts([X_train[0]])[0]\n",
        "print (\"Text to indices:\\n\"\n",
        "    f\"  (preprocessed) → {preprocessed_text}\\n\"\n",
        "    f\"  (tokenized) → {X_train[0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Text to indices:\n",
            "  (preprocessed) → <UNK> <UNK> <UNK> <UNK> <UNK>\n",
            "  (tokenized) → [1 1 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwrOgDaMD8eW"
      },
      "source": [
        "def to_categorical(seq, num_classes):\n",
        "    \"\"\"one-hot encode a sequence of tokens\"\"\"\n",
        "    one_hot = np.zeros((len(seq), num_classes))\n",
        "    for i, item in enumerate(seq):\n",
        "        one_hot[i, item] = 1\n",
        "    return one_hot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCDWGRoDEvFW",
        "outputId": "9310175a-3e73-4816-870e-400fbcfa5209"
      },
      "source": [
        "# One-hot encoding\n",
        "print (X_train[0])\n",
        "print (len(X_train[0]))\n",
        "cat = to_categorical(seq=X_train[0], num_classes=len(tokenizer))\n",
        "print (cat)\n",
        "print (cat.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1]\n",
            "5\n",
            "[[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]]\n",
            "(5, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19z5mRaAE0tf"
      },
      "source": [
        "# Convert tokens to one-hot\n",
        "vocab_size = len(tokenizer)\n",
        "X_train = [to_categorical(seq, num_classes=vocab_size) for seq in X_train]\n",
        "X_val = [to_categorical(seq, num_classes=vocab_size) for seq in X_val]\n",
        "X_test = [to_categorical(seq, num_classes=vocab_size) for seq in X_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ye__0fCFkZZ"
      },
      "source": [
        "# one hot encode: (N, max_seq_len, vocab_size)\n",
        "def pad_sequences(sequences, max_seq_len=0):\n",
        "    \"\"\"pad sequences to max length in sequence\"\"\"\n",
        "    max_seq_len = max(max_seq_len, max(len(sequence) for sequence in sequences))\n",
        "    num_classes = sequences[0].shape[-1]\n",
        "    padded_sequences = np.zeros((len(sequences), max_seq_len, num_classes))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        padded_sequences[i][:len(sequence)] = sequence\n",
        "    return padded_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIoO92-ylRcL",
        "outputId": "4ae64919-2f9a-4714-9e00-c7a78c22f36c"
      },
      "source": [
        "# 3D sequences\n",
        "print (X_train[0].shape, X_train[1].shape, X_train[2].shape)\n",
        "padded = pad_sequences(X_train[0:3])\n",
        "print (padded.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 500) (6, 500) (7, 500)\n",
            "(3, 7, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIwzh9KWlSyL",
        "outputId": "e5371143-6276-4bb9-95ec-6d76e521cd38"
      },
      "source": [
        "padded"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 1., 0., ..., 0., 0., 0.],\n",
              "        [0., 1., 0., ..., 0., 0., 0.],\n",
              "        [0., 1., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 1., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 1., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 1., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 1., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 1., 0., ..., 0., 0., 0.],\n",
              "        [0., 1., 0., ..., 0., 0., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVeGDFswlrk4"
      },
      "source": [
        "# Dataset\n",
        "FILTER_SIZE = 1 #unigram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyUTDgkNl_pq"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, max_filter_size):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.max_filter_size = max_filter_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Dataset(N={len(self)})>\"\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X = self.X[index]\n",
        "        y = self.y[index]\n",
        "        return [X, y]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        batch = np.array(batch, dtype=object)\n",
        "        X = batch[:, 0]\n",
        "        y = np.stack(batch[:,1], axis=0)\n",
        "\n",
        "        # pad sequences\n",
        "        X = pad_sequences(X, max_seq_len=self.max_filter_size)\n",
        "\n",
        "        X = torch.FloatTensor(X.astype(np.int32))\n",
        "        y = torch.LongTensor(y.astype(np.int32))\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def create_dataloader(self, batch_size, shuffle=False, drop_last=False):\n",
        "        return torch.utils.data.DataLoader(dataset=self, batch_size=batch_size,\n",
        "                                           collate_fn=self.collate_fn, \n",
        "                                           shuffle=shuffle, drop_last=drop_last,\n",
        "                                           pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpl_5xGjok0H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "775ad01a-5e91-463f-9e6e-396e7d211c78"
      },
      "source": [
        "train_dataset = Dataset(X=X_train, y=y_train, max_filter_size=FILTER_SIZE)\n",
        "val_dataset = Dataset(X=X_val, y=y_val, max_filter_size=FILTER_SIZE)\n",
        "test_dataset = Dataset(X=X_test, y=y_test, max_filter_size=FILTER_SIZE)\n",
        "print (\"Datasets:\\n\"\n",
        "    f\"  Train dataset:{train_dataset.__str__()}\\n\"\n",
        "    f\"  Val dataset: {val_dataset.__str__()}\\n\"\n",
        "    f\"  Test dataset: {test_dataset.__str__()}\\n\"\n",
        "    \"Sample point:\\n\"\n",
        "    f\"  X: {test_dataset[0][0]}\\n\"\n",
        "    f\"  y: {test_dataset[0][1]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datasets:\n",
            "  Train dataset:<Dataset(N=84000)>\n",
            "  Val dataset: <Dataset(N=18000)>\n",
            "  Test dataset: <Dataset(N=18000)>\n",
            "Sample point:\n",
            "  X: [[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]]\n",
            "  y: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKbbLmGfrxFU",
        "outputId": "384ed90d-fd3e-4c07-fb19-f0adf0d0edea"
      },
      "source": [
        "# Create dataloaders\n",
        "batch_size = 64\n",
        "train_dataloader = train_dataset.create_dataloader(batch_size=batch_size)\n",
        "val_dataloader = val_dataset.create_dataloader(batch_size=batch_size)\n",
        "test_dataloader = test_dataset.create_dataloader(batch_size=batch_size)\n",
        "batch_X, batch_y = next(iter(test_dataloader))\n",
        "print (\"Sample batch:\\n\"\n",
        "    f\"  X: {list(batch_X.size())}\\n\"\n",
        "    f\"  y: {list(batch_y.size())}\\n\"\n",
        "    \"Sample point:\\n\"\n",
        "    f\"  X: {batch_X[0]}\\n\"\n",
        "    f\"  y: {batch_y[0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample batch:\n",
            "  X: [64, 13, 500]\n",
            "  y: [64]\n",
            "Sample point:\n",
            "  X: tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "  y: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3OAPjZ9JE-j"
      },
      "source": [
        "# Dummy CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEsSDsioo-n8"
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Rw-rOSqJCUD",
        "outputId": "daeb9bc8-7488-426a-8e5a-96e3b84ff33f"
      },
      "source": [
        "batch_size = 64\n",
        "max_seq_len = 8 # words per input\n",
        "vocab_size = 10 # one hot size\n",
        "x = torch.randn(batch_size, max_seq_len, vocab_size)\n",
        "print(f\"X: {x.shape}\")\n",
        "x = x.transpose(1,2)\n",
        "print(f\"X: {x.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X: torch.Size([64, 8, 10])\n",
            "X: torch.Size([64, 10, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X95GSD78Jc6C",
        "outputId": "6e53bc17-39c7-49ef-9150-450a6c20c65b"
      },
      "source": [
        "# conv filters (VALID padding)\n",
        "vocab_size = 10\n",
        "num_filters = 50\n",
        "filter_size = 3\n",
        "stride = 1\n",
        "padding = 0\n",
        "conv1 = nn.Conv1d(in_channels=vocab_size, out_channels=num_filters, \n",
        "                  kernel_size=filter_size, stride=stride, padding=padding,\n",
        "                  padding_mode='zeros')\n",
        "print(\"conv: {}\".format(conv1.weight.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv: torch.Size([50, 10, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_po-1RiJx8y",
        "outputId": "e5be43cb-b64e-43a9-d5ea-5c19fcda2b08"
      },
      "source": [
        "# Forward pass\n",
        "z = conv1(x)\n",
        "print (f\"z: {z.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "z: torch.Size([64, 50, 6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1W_GL5ayL6MA",
        "outputId": "8ff4b8ae-5876-4629-ea12-07ba74a4386b"
      },
      "source": [
        "# Convolutional filters (SAME padding)\n",
        "vocab_size = 10 # one hot size\n",
        "num_filters = 50 # num filters\n",
        "filter_size = 3 # filters are 3X3\n",
        "stride = 1\n",
        "conv = nn.Conv1d(in_channels=vocab_size, out_channels=num_filters,\n",
        "                 kernel_size=filter_size, stride=stride)\n",
        "print(\"conv: {}\".format(conv.weight.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv: torch.Size([50, 10, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_r8EGZsMFfQ",
        "outputId": "509fcdcc-4855-410d-a93f-3beeef4bd88c"
      },
      "source": [
        "# `SAME` padding\n",
        "padding_left = int((conv.stride[0]*(max_seq_len-1) - max_seq_len + filter_size)/2)\n",
        "padding_right = int(math.ceil((conv.stride[0]*(max_seq_len-1) - max_seq_len + filter_size)/2))\n",
        "print (f\"padding: {(padding_left, padding_right)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "padding: (1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlSj0KE0MMzv",
        "outputId": "f9f86e40-c29e-49eb-bc5c-8633118bc570"
      },
      "source": [
        "# Forward pass\n",
        "z = conv(F.pad(x, (padding_left, padding_right)))\n",
        "print (f\"z: {z.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "z: torch.Size([64, 50, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQYo440SMUxP",
        "outputId": "629535e0-2b70-47a9-cc44-589e8bcb48f4"
      },
      "source": [
        "# Max pooling\n",
        "pool_output = F.max_pool1d(z, z.size(2))\n",
        "print(\"Size: {}\".format(pool_output.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([64, 50, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC0KVRdNSD4E",
        "outputId": "2b78a4d6-2cb2-429e-820a-78c1a261d69c"
      },
      "source": [
        "# Batch normalization\n",
        "batch_norm = nn.BatchNorm1d(num_features=num_filters)\n",
        "z = batch_norm(conv(x)) # applied to activations (after conv layer & before pooling)\n",
        "print (f\"z: {z.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "z: torch.Size([64, 50, 6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JiL_KySSN9B",
        "outputId": "e629735c-5629-45cd-b089-0fdd9b98c9af"
      },
      "source": [
        "# Mean and std before batchnorm\n",
        "print (f\"mean: {torch.mean(conv1(x)):.2f}, std: {torch.std(conv(x)):.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean: -0.01, std: 0.57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-4pIpuCSPfB",
        "outputId": "002dcb0b-80a8-4e77-cdf2-ea3b7051d3f5"
      },
      "source": [
        "# Mean and std after batchnorm\n",
        "print (f\"mean: {torch.mean(z):.2f}, std: {torch.std(z):.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean: -0.00, std: 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6SnYCbySR-j"
      },
      "source": [
        "NUM_FILTERS = 50\n",
        "HIDDEN_DIM = 100\n",
        "DROPOUT_P = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "retsjV4mStuB"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, num_filters, filter_size,\n",
        "                 hidden_dim, dropout_p, num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.filter_size = filter_size\n",
        "        self.conv = nn.Conv1d(in_channels=vocab_size, out_channels=num_filters,\n",
        "                              kernel_size=filter_size, stride=1, padding=0,\n",
        "                              padding_mode='zeros')\n",
        "        self.batch_norm = nn.BatchNorm1d(num_features=num_filters)\n",
        "\n",
        "        self.fc1 = nn.Linear(num_filters, hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, inputs, channel_first=False, apply_softmax=False):\n",
        "        x_in, = inputs\n",
        "        if not channel_first:\n",
        "            x_in = x_in.transpose(1, 2) #(N, C, L)\n",
        "        \n",
        "        # paddding for SAME padding\n",
        "        max_seq_len = x_in.shape[2]\n",
        "        padding_left = int((self.conv.stride[0]*(max_seq_len-1) - max_seq_len + self.filter_size)/2)\n",
        "        padding_right = int(math.ceil((self.conv.stride[0]*(max_seq_len-1) - max_seq_len + self.filter_size)/2))\n",
        "\n",
        "        # conv\n",
        "        z = self.conv(F.pad(x_in, (padding_left, padding_right)))\n",
        "        z = F.max_pool1d(z, z.size(2)).squeeze(2)\n",
        "\n",
        "        # FC layer\n",
        "        z = self.fc1(z)\n",
        "        z = self.dropout(z)\n",
        "        y_pred = self.fc2(z)\n",
        "\n",
        "        if apply_softmax:\n",
        "            y_pred = F.softmax(y_pred, dim=1)\n",
        "        return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjpQPDy7jwCI",
        "outputId": "40055bae-75df-4779-88d6-7d8c8c5824ec"
      },
      "source": [
        "# Initialize model\n",
        "model = CNN(vocab_size=VOCAB_SIZE, num_filters=NUM_FILTERS, filter_size=FILTER_SIZE,\n",
        "            hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)\n",
        "model = model.to(device) # set device\n",
        "print (model.named_parameters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.named_parameters of CNN(\n",
            "  (conv): Conv1d(500, 50, kernel_size=(1,), stride=(1,))\n",
            "  (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc1): Linear(in_features=50, out_features=100, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6t-tkSOj_V5"
      },
      "source": [
        "from torch.optim import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpAHUpsfkLln"
      },
      "source": [
        "LEARNING_RATE = 1e-3\n",
        "PATIENCE = 5\n",
        "NUM_EPOCHS = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoiFBbcrkYvW"
      },
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, model, device, loss_fn=None, optimizer=None, scheduler=None):\n",
        "\n",
        "        # Set params\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "    def train_step(self, dataloader):\n",
        "        \"\"\"Train step.\"\"\"\n",
        "        # Set model to train mode\n",
        "        self.model.train()\n",
        "        loss = 0.0\n",
        "\n",
        "        # Iterate over train batches\n",
        "        for i, batch in enumerate(dataloader):\n",
        "\n",
        "            # Step\n",
        "            batch = [item.to(self.device) for item in batch]  # Set device\n",
        "            inputs, targets = batch[:-1], batch[-1]\n",
        "            self.optimizer.zero_grad()  # Reset gradients\n",
        "            z = self.model(inputs)  # Forward pass\n",
        "            J = self.loss_fn(z, targets)  # Define loss\n",
        "            J.backward()  # Backward pass\n",
        "            self.optimizer.step()  # Update weights\n",
        "\n",
        "            # Cumulative Metrics\n",
        "            loss += (J.detach().item() - loss) / (i + 1)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def eval_step(self, dataloader):\n",
        "        \"\"\"Validation or test step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        loss = 0.0\n",
        "        y_trues, y_probs = [], []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Step\n",
        "                batch = [item.to(self.device) for item in batch]  # Set device\n",
        "                inputs, y_true = batch[:-1], batch[-1]\n",
        "                z = self.model(inputs)  # Forward pass\n",
        "                J = self.loss_fn(z, y_true).item()\n",
        "\n",
        "                # Cumulative Metrics\n",
        "                loss += (J - loss) / (i + 1)\n",
        "\n",
        "                # Store outputs\n",
        "                y_prob = torch.sigmoid(z).cpu().numpy()\n",
        "                y_probs.extend(y_prob)\n",
        "                y_trues.extend(y_true.cpu().numpy())\n",
        "\n",
        "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
        "\n",
        "    def predict_step(self, dataloader):\n",
        "        \"\"\"Prediction step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        y_probs = []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Forward pass w/ inputs\n",
        "                inputs, targets = batch[:-1], batch[-1]\n",
        "                y_prob = self.model(inputs, apply_softmax=True)\n",
        "\n",
        "                # Store outputs\n",
        "                y_probs.extend(y_prob)\n",
        "\n",
        "        return np.vstack(y_probs)\n",
        "\n",
        "    def train(self, num_epochs, patience, train_dataloader, val_dataloader):\n",
        "        best_val_loss = np.inf\n",
        "        for epoch in range(num_epochs):\n",
        "            # Steps\n",
        "            train_loss = self.train_step(dataloader=train_dataloader)\n",
        "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
        "            self.scheduler.step(val_loss)\n",
        "\n",
        "            # Early stopping\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = self.model\n",
        "                _patience = patience  # reset _patience\n",
        "            else:\n",
        "                _patience -= 1\n",
        "            if not _patience:  # 0\n",
        "                print(\"Stopping early!\")\n",
        "                break\n",
        "\n",
        "            # Logging\n",
        "            print(\n",
        "                f\"Epoch: {epoch+1} | \"\n",
        "                f\"train_loss: {train_loss:.5f}, \"\n",
        "                f\"val_loss: {val_loss:.5f}, \"\n",
        "                f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
        "                f\"_patience: {_patience}\"\n",
        "            )\n",
        "        return best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8snMT-qQqVie"
      },
      "source": [
        "# Define Loss\n",
        "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWtVGFDPqt3H"
      },
      "source": [
        "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.1, patience=3\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot71Z9WlrVz5"
      },
      "source": [
        "# Trainer module\n",
        "trainer = Trainer(\n",
        "    model=model, device=device, loss_fn=loss_fn,\n",
        "    optimizer=optimizer, scheduler=scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgLLlav4rZCD",
        "outputId": "515a4715-d477-4bd8-d0e6-a624fb1d3543"
      },
      "source": [
        "# Train\n",
        "best_model = trainer.train(\n",
        "    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.87731, val_loss: 0.78343, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 2 | train_loss: 0.78640, val_loss: 0.77561, lr: 1.00E-03, _patience: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKS-VVrwrdZ7"
      },
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puNyw8rztoqj"
      },
      "source": [
        "def get_metrics(y_true, y_pred, classes):\n",
        "    \"\"\"Per-class performance metrics.\"\"\"\n",
        "    # Performance\n",
        "    performance = {\"overall\": {}, \"class\": {}}\n",
        "\n",
        "    # Overall performance\n",
        "    metrics = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "    performance[\"overall\"][\"precision\"] = metrics[0]\n",
        "    performance[\"overall\"][\"recall\"] = metrics[1]\n",
        "    performance[\"overall\"][\"f1\"] = metrics[2]\n",
        "    performance[\"overall\"][\"num_samples\"] = np.float64(len(y_true))\n",
        "\n",
        "    # Per-class performance\n",
        "    metrics = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
        "    for i in range(len(classes)):\n",
        "        performance[\"class\"][classes[i]] = {\n",
        "            \"precision\": metrics[0][i],\n",
        "            \"recall\": metrics[1][i],\n",
        "            \"f1\": metrics[2][i],\n",
        "            \"num_samples\": np.float64(metrics[3][i]),\n",
        "        }\n",
        "\n",
        "    return performance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prSnksFCtqtb"
      },
      "source": [
        "# Get predictions\n",
        "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
        "y_pred = np.argmax(y_prob, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afkx6A1Ztt7i",
        "outputId": "89ce3147-c514-411d-c4a7-103e703ab7b2"
      },
      "source": [
        "# Determine performance\n",
        "performance = get_metrics(\n",
        "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
        "print (json.dumps(performance['overall'], indent=2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"precision\": 0.7108799265528744,\n",
            "  \"recall\": 0.6883333333333334,\n",
            "  \"f1\": 0.6889996132023932,\n",
            "  \"num_samples\": 18000.0\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT9bce8EtvKC"
      },
      "source": [
        "# Save artifacts\n",
        "dir = Path(\"cnn\")\n",
        "dir.mkdir(parents=True, exist_ok=True)\n",
        "label_encoder.save(fp=Path(dir, 'label_encoder.json'))\n",
        "tokenizer.save(fp=Path(dir, 'tokenizer.json'))\n",
        "torch.save(best_model.state_dict(), Path(dir, 'model.pt'))\n",
        "with open(Path(dir, 'performance.json'), \"w\") as fp:\n",
        "    json.dump(performance, indent=2, sort_keys=False, fp=fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3pagTLHt1cB"
      },
      "source": [
        "def get_probability_distribution(y_prob, classes):\n",
        "    \"\"\"Create a dict of class probabilities from an array.\"\"\"\n",
        "    results = {}\n",
        "    for i, class_ in enumerate(classes):\n",
        "        results[class_] = np.float64(y_prob[i])\n",
        "    sorted_results = {k: v for k, v in sorted(\n",
        "        results.items(), key=lambda item: item[1], reverse=True)}\n",
        "    return sorted_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPSJiPa6uulP",
        "outputId": "fd059154-53fc-49a1-f1bc-160c9c293106"
      },
      "source": [
        "# Load artifacts\n",
        "device = torch.device(\"cpu\")\n",
        "label_encoder = LabelEncoder.load(fp=Path(dir, 'label_encoder.json'))\n",
        "tokenizer = Tokenizer.load(fp=Path(dir, 'tokenizer.json'))\n",
        "model = CNN(\n",
        "    vocab_size=VOCAB_SIZE, num_filters=NUM_FILTERS, filter_size=FILTER_SIZE,\n",
        "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)\n",
        "model.load_state_dict(torch.load(Path(dir, 'model.pt'), map_location=device))\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv): Conv1d(500, 50, kernel_size=(1,), stride=(1,))\n",
              "  (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc1): Linear(in_features=50, out_features=100, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OLDgBqKuwGq"
      },
      "source": [
        "# Initialize trainer\n",
        "trainer = Trainer(model=model, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHohJ2HPxRmP",
        "outputId": "d2d02951-3c77-4e79-b3e7-2b2a8a71f2c1"
      },
      "source": [
        "# Dataloader\n",
        "text = \"What a day for the new york stock market to go bust!\"\n",
        "sequences = tokenizer.texts_to_sequences([preprocess(text)])\n",
        "print (tokenizer.sequences_to_texts(sequences))\n",
        "X = [to_categorical(seq, num_classes=len(tokenizer)) for seq in sequences]\n",
        "y_filler = label_encoder.encode([label_encoder.classes[0]]*len(X))\n",
        "dataset = Dataset(X=X, y=y_filler, max_filter_size=FILTER_SIZE)\n",
        "dataloader = dataset.create_dataloader(batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "['day new <UNK> stock market go <UNK>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAW2HlaBxeHe",
        "outputId": "c5fb4c3c-76d0-445f-8e55-f142b2b39255"
      },
      "source": [
        "# Inference\n",
        "y_prob = trainer.predict_step(dataloader)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "label_encoder.decode(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Business']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5pjIQDwxhrN",
        "outputId": "b1bdc59d-5abd-4eeb-8ed3-0ac6044da347"
      },
      "source": [
        "# Class distributions\n",
        "prob_dist = get_probability_distribution(y_prob=y_prob[0], classes=label_encoder.classes)\n",
        "print (json.dumps(prob_dist, indent=2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"Business\": 0.8779469132423401,\n",
            "  \"Sci/Tech\": 0.10688897967338562,\n",
            "  \"World\": 0.012356700375676155,\n",
            "  \"Sports\": 0.0028073955327272415\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltPmphRjxkEY"
      },
      "source": [
        "import collections\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfjC_nE-xp2Y"
      },
      "source": [
        "class InterpretableCNN(nn.Module):\n",
        "    def __init__(self, vocab_size, num_filters, filter_size,\n",
        "                 hidden_dim, dropout_p, num_classes):\n",
        "        super(InterpretableCNN, self).__init__()\n",
        "\n",
        "        # Convolutional filters\n",
        "        self.filter_size = filter_size\n",
        "        self.conv = nn.Conv1d(\n",
        "            in_channels=vocab_size, out_channels=num_filters,\n",
        "            kernel_size=filter_size, stride=1, padding=0, padding_mode='zeros')\n",
        "        self.batch_norm = nn.BatchNorm1d(num_features=num_filters)\n",
        "\n",
        "        # FC layers\n",
        "        self.fc1 = nn.Linear(num_filters, hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, inputs, channel_first=False, apply_softmax=False):\n",
        "\n",
        "        # Rearrange input so num_channels is in dim 1 (N, C, L)\n",
        "        x_in, = inputs\n",
        "        if not channel_first:\n",
        "            x_in = x_in.transpose(1, 2)\n",
        "\n",
        "        # Padding for `SAME` padding\n",
        "        max_seq_len = x_in.shape[2]\n",
        "        padding_left = int((self.conv.stride[0]*(max_seq_len-1) - max_seq_len + self.filter_size)/2)\n",
        "        padding_right = int(math.ceil((self.conv.stride[0]*(max_seq_len-1) - max_seq_len + self.filter_size)/2))\n",
        "\n",
        "        # Conv outputs\n",
        "        z = self.conv(F.pad(x_in, (padding_left, padding_right)))\n",
        "\n",
        "        return z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOUr553kxytJ"
      },
      "source": [
        "# Initialize\n",
        "interpretable_model = InterpretableCNN(\n",
        "    vocab_size=len(tokenizer), num_filters=NUM_FILTERS, filter_size=FILTER_SIZE,\n",
        "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbaBVT3gx0tJ",
        "outputId": "43cbc5d7-64d5-4976-8885-62ca5c5e7684"
      },
      "source": [
        "# Load weights (same architecture)\n",
        "interpretable_model.load_state_dict(torch.load(Path(dir, 'model.pt'), map_location=device))\n",
        "interpretable_model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InterpretableCNN(\n",
              "  (conv): Conv1d(500, 50, kernel_size=(1,), stride=(1,))\n",
              "  (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc1): Linear(in_features=50, out_features=100, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7Y2gdXRx5hx"
      },
      "source": [
        "# Initialize trainer\n",
        "interpretable_trainer = Trainer(model=interpretable_model, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbYaO6GMx8Eg",
        "outputId": "95e26f04-36dc-44b9-8aa6-b7b97780b9fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Get conv outputs\n",
        "conv_outputs = interpretable_trainer.predict_step(dataloader)\n",
        "print (conv_outputs.shape) # (num_filters, max_seq_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65itkMs_x9zZ",
        "outputId": "a2118a78-a6e2-461a-a72f-960b2f93ed00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "# Visualize a bi-gram filter's outputs\n",
        "tokens = tokenizer.sequences_to_texts(sequences)[0].split(' ')\n",
        "sns.heatmap(conv_outputs, xticklabels=tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7176bcefd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEgQYjKxyAQK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}